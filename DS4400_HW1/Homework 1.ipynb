{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS44000 Homework 1\n",
    "\n",
    "Chris Dilger\n",
    "\n",
    "Code available on GitHub: https://github.com/cdilga/DS4400/blob/master/Homework%201.ipynb\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "## Problem 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>520414.834000</td>\n",
       "      <td>339488.477270</td>\n",
       "      <td>80000.0000</td>\n",
       "      <td>3.075000e+06</td>\n",
       "      <td>1.152524e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>3.349000</td>\n",
       "      <td>0.852012</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>7.259249e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>2.045750</td>\n",
       "      <td>0.721623</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.207402e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living</th>\n",
       "      <td>2051.196000</td>\n",
       "      <td>887.929222</td>\n",
       "      <td>380.0000</td>\n",
       "      <td>6.070000e+03</td>\n",
       "      <td>7.884183e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot</th>\n",
       "      <td>14702.085000</td>\n",
       "      <td>28961.030775</td>\n",
       "      <td>649.0000</td>\n",
       "      <td>3.153740e+05</td>\n",
       "      <td>8.387413e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floors</th>\n",
       "      <td>1.446500</td>\n",
       "      <td>0.517354</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>2.676554e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterfront</th>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.089129</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.943944e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>view</th>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.765125</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>5.854164e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <td>3.464000</td>\n",
       "      <td>0.689332</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>4.751792e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>7.606000</td>\n",
       "      <td>1.160220</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>1.346110e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_above</th>\n",
       "      <td>1750.333000</td>\n",
       "      <td>790.077476</td>\n",
       "      <td>380.0000</td>\n",
       "      <td>6.070000e+03</td>\n",
       "      <td>6.242224e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_basement</th>\n",
       "      <td>300.863000</td>\n",
       "      <td>450.898196</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.060000e+03</td>\n",
       "      <td>2.033092e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr_built</th>\n",
       "      <td>1969.049000</td>\n",
       "      <td>28.190873</td>\n",
       "      <td>1900.0000</td>\n",
       "      <td>2.015000e+03</td>\n",
       "      <td>7.947253e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr_renovated</th>\n",
       "      <td>81.749000</td>\n",
       "      <td>395.578250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.014000e+03</td>\n",
       "      <td>1.564822e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>47.549493</td>\n",
       "      <td>0.141670</td>\n",
       "      <td>47.1775</td>\n",
       "      <td>4.777760e+01</td>\n",
       "      <td>2.007034e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>-122.207472</td>\n",
       "      <td>0.139509</td>\n",
       "      <td>-122.4900</td>\n",
       "      <td>-1.217090e+02</td>\n",
       "      <td>1.946285e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living15</th>\n",
       "      <td>1987.077000</td>\n",
       "      <td>670.439353</td>\n",
       "      <td>830.0000</td>\n",
       "      <td>4.760000e+03</td>\n",
       "      <td>4.494889e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot15</th>\n",
       "      <td>13496.874000</td>\n",
       "      <td>25093.829486</td>\n",
       "      <td>660.0000</td>\n",
       "      <td>2.339710e+05</td>\n",
       "      <td>6.297003e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean            std         min           max  \\\n",
       "price          520414.834000  339488.477270  80000.0000  3.075000e+06   \n",
       "bedrooms            3.349000       0.852012      0.0000  7.000000e+00   \n",
       "bathrooms           2.045750       0.721623      0.0000  5.000000e+00   \n",
       "sqft_living      2051.196000     887.929222    380.0000  6.070000e+03   \n",
       "sqft_lot        14702.085000   28961.030775    649.0000  3.153740e+05   \n",
       "floors              1.446500       0.517354      1.0000  3.500000e+00   \n",
       "waterfront          0.008000       0.089129      0.0000  1.000000e+00   \n",
       "view                0.237000       0.765125      0.0000  4.000000e+00   \n",
       "condition           3.464000       0.689332      1.0000  5.000000e+00   \n",
       "grade               7.606000       1.160220      4.0000  1.200000e+01   \n",
       "sqft_above       1750.333000     790.077476    380.0000  6.070000e+03   \n",
       "sqft_basement     300.863000     450.898196      0.0000  2.060000e+03   \n",
       "yr_built         1969.049000      28.190873   1900.0000  2.015000e+03   \n",
       "yr_renovated       81.749000     395.578250      0.0000  2.014000e+03   \n",
       "lat                47.549493       0.141670     47.1775  4.777760e+01   \n",
       "long             -122.207472       0.139509   -122.4900 -1.217090e+02   \n",
       "sqft_living15    1987.077000     670.439353    830.0000  4.760000e+03   \n",
       "sqft_lot15      13496.874000   25093.829486    660.0000  2.339710e+05   \n",
       "\n",
       "                        var  \n",
       "price          1.152524e+11  \n",
       "bedrooms       7.259249e-01  \n",
       "bathrooms      5.207402e-01  \n",
       "sqft_living    7.884183e+05  \n",
       "sqft_lot       8.387413e+08  \n",
       "floors         2.676554e-01  \n",
       "waterfront     7.943944e-03  \n",
       "view           5.854164e-01  \n",
       "condition      4.751792e-01  \n",
       "grade          1.346110e+00  \n",
       "sqft_above     6.242224e+05  \n",
       "sqft_basement  2.033092e+05  \n",
       "yr_built       7.947253e+02  \n",
       "yr_renovated   1.564822e+05  \n",
       "lat            2.007034e-02  \n",
       "long           1.946285e-02  \n",
       "sqft_living15  4.494889e+05  \n",
       "sqft_lot15     6.297003e+08  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cols(data, width = 30):\n",
    "    \"\"\"Formats list like objects into columns\"\"\"\n",
    "    return \"\".join(str(word).ljust(30) for word in data)\n",
    "\n",
    "                   \n",
    "# Load the file\n",
    "housing = pd.read_csv(\"data/train.csv\", \n",
    "                      usecols=lambda x: x in [\"price\",\n",
    "                                              \"bedrooms\",\n",
    "                                              \"bathrooms\",\n",
    "                                              \"sqft_living\",\n",
    "                                              \"sqft_lot\",\n",
    "                                              \"floors\",\n",
    "                                              \"waterfront\",\n",
    "                                              \"view\",\n",
    "                                              \"condition\",\n",
    "                                              \"grade\",\n",
    "                                              \"sqft_above\",\n",
    "                                              \"sqft_basement\",\n",
    "                                              \"yr_built\",\n",
    "                                              \"yr_renovated\",\n",
    "                                              \"lat\",\n",
    "                                              \"long\",\n",
    "                                              \"sqft_living15\",\n",
    "                                              \"sqft_lot15\"])\n",
    "\n",
    "housing_test = pd.read_csv(\"data/test.csv\", \n",
    "                      usecols=lambda x: x in [\"price\",\n",
    "                                              \"bedrooms\",\n",
    "                                              \"bathrooms\",\n",
    "                                              \"sqft_living\",\n",
    "                                              \"sqft_lot\",\n",
    "                                              \"floors\",\n",
    "                                              \"waterfront\",\n",
    "                                              \"view\",\n",
    "                                              \"condition\",\n",
    "                                              \"grade\",\n",
    "                                              \"sqft_above\",\n",
    "                                              \"sqft_basement\",\n",
    "                                              \"yr_built\",\n",
    "                                              \"yr_renovated\",\n",
    "                                              \"lat\",\n",
    "                                              \"long\",\n",
    "                                              \"sqft_living15\",\n",
    "                                              \"sqft_lot15\"])\n",
    "\n",
    "\n",
    "housing_training_features = housing.copy().drop(\"price\", axis=1)\n",
    "housing_training_labels = housing.copy().loc[:,\"price\"]\n",
    "housing_testing_features = housing_test.copy().drop(\"price\", axis=1)\n",
    "housing_testing_labels = housing_test.copy().loc[:,\"price\"]\n",
    "\n",
    "description = housing.describe().loc[[\"mean\", \"std\", \"min\", \"max\"]]\n",
    "description = description.T\n",
    "description['var'] = description['std'].apply(lambda x: x**2)\n",
    "description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedrooms                      0.3070584002104321            0.3070584002104319            \n",
      "bathrooms                     0.48715729789866974           0.4871572978986769            \n",
      "sqft_living                   0.7047757101823997            0.7047757101824055            \n",
      "sqft_lot                      0.14664482983805222           0.14664482983805197           \n",
      "floors                        0.2399348472639126            0.2399348472639161            \n",
      "waterfront                    0.31714301382621846           0.3171430138262226            \n",
      "view                          0.44531642588846515           0.4453164258884609            \n",
      "condition                     0.07396055390188862           0.07396055390188938           \n",
      "grade                         0.647349055785599             0.6473490557856066            \n",
      "sqft_above                    0.5824071469756538            0.5824071469756582            \n",
      "sqft_basement                 0.3673649191324655            0.36736491913246594           \n",
      "yr_built                      0.01605485919669362           0.016054859196693777          \n",
      "yr_renovated                  0.1463481824398023            0.14634818243980063           \n",
      "lat                           0.36576970790785424           0.36576970790785757           \n",
      "long                          0.0328455635948112            0.03284556359481139           \n",
      "sqft_living15                 0.6451060081578837            0.6451060081578872            \n",
      "sqft_lot15                    0.16174626078384294           0.16174626078384322           \n"
     ]
    }
   ],
   "source": [
    "def cov(x, y):\n",
    "    \"\"\"Calculate covariance given the feature x and response y\"\"\"\n",
    "    total = 0\n",
    "    x_m = x.mean()\n",
    "    y_m = y.mean()\n",
    "    for i in range(len(x)):\n",
    "        total += (x.loc[i]-x_m)*(y.loc[i]-y_m)\n",
    "    return total/(len(x)-1)\n",
    "\n",
    "def cor(x, y):\n",
    "    \"\"\"Calculate the correlation coefficient\"\"\"\n",
    "    return cov(x, y)/(x.std()*y.std())\n",
    "\n",
    "for feature in [x for x in housing if x != \"price\"]:\n",
    "    print(cols([feature, \n",
    "                cor(housing[\"price\"], housing[feature]),\n",
    "                housing[\"price\"].corr(housing[feature])\n",
    "               ]))\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion of Problem 1.a\n",
    "Suprisingly every feature is positively correlated with price, which is suprising. `yr_built` and `yr_renovated` are weakly correlated, as were `long` (longditude) and `sqft_lot15`. \n",
    "\n",
    "\n",
    "## Problem 2 [Linear regression]\n",
    "\n",
    "### (a) \n",
    "Use an existing package to train a linear regression model on the training set. Report the coefficients of the linear regression models and the 3 metrics of interest: MSE, RSS, and $R^2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$R^2 = 0.7265$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$MSE=31486167776$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$RSS=31486167775795$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use scikit.learn\n",
    "\n",
    "#Get MSE RSS and R^2\n",
    "\n",
    "#All predictors predicting 'price' label\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from IPython.display import display, Math\n",
    "from sklearn import metrics\n",
    "\n",
    "def lib_metrics(r, features, labels):\n",
    "    display(Math(\"R^2 = {0:.4f}\".format(r.score(features, labels))))\n",
    "    mse = metrics.mean_squared_error(labels, r.predict(features))\n",
    "    display(Math(\"MSE={0:.0f}\".format(mse)))\n",
    "\n",
    "    rss = mse*len(labels)\n",
    "    display(Math(\"RSS={0:.0f}\".format(rss)))\n",
    "\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(housing_training_features, housing_training_labels)\n",
    "\n",
    "lib_metrics(reg, housing_training_features, housing_training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) \n",
    "Perform feature standardization so that each feature has mean 0 and variance of 1. Train again a linear regression model on the training data. Compare the results with the previous models in terms of the metrics of interest: MSE, RSS, and $R^2$.\n",
    "\n",
    "### (c)\n",
    "Evaluate both models on the testing set. Report the same metrics (MSE, RSE, and $R^2$) on the testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$R^2 = 0.7265$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$MSE=31486167776$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$RSS=31486167775795$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Scaling R^2:  0.7265334318706016\n",
      "With Scaling R^2:  0.7265334318706018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standardized</th>\n",
       "      <th>Unstandardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>-1035.203084</td>\n",
       "      <td>-7424.027121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floors</th>\n",
       "      <td>8043.720837</td>\n",
       "      <td>15555.580988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot</th>\n",
       "      <td>10881.868446</td>\n",
       "      <td>0.375930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>-12521.961869</td>\n",
       "      <td>-14704.280497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot15</th>\n",
       "      <td>-12930.090978</td>\n",
       "      <td>-0.515528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <td>12964.269364</td>\n",
       "      <td>18816.402756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr_renovated</th>\n",
       "      <td>17271.379530</td>\n",
       "      <td>43.682942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>18527.632513</td>\n",
       "      <td>25687.783987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_basement</th>\n",
       "      <td>27137.032468</td>\n",
       "      <td>41.073715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living15</th>\n",
       "      <td>45577.657813</td>\n",
       "      <td>68.015792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>view</th>\n",
       "      <td>48200.108524</td>\n",
       "      <td>63027.898001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_above</th>\n",
       "      <td>48290.088862</td>\n",
       "      <td>42.010495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living</th>\n",
       "      <td>56748.836801</td>\n",
       "      <td>83.084210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterfront</th>\n",
       "      <td>63742.899560</td>\n",
       "      <td>715535.170469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr_built</th>\n",
       "      <td>-67643.117413</td>\n",
       "      <td>-2400.669330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>78375.736932</td>\n",
       "      <td>553505.032276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>92231.474822</td>\n",
       "      <td>79534.602722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Standardized  Unstandardized\n",
       "long           -1035.203084    -7424.027121\n",
       "floors          8043.720837    15555.580988\n",
       "sqft_lot       10881.868446        0.375930\n",
       "bedrooms      -12521.961869   -14704.280497\n",
       "sqft_lot15    -12930.090978       -0.515528\n",
       "condition      12964.269364    18816.402756\n",
       "yr_renovated   17271.379530       43.682942\n",
       "bathrooms      18527.632513    25687.783987\n",
       "sqft_basement  27137.032468       41.073715\n",
       "sqft_living15  45577.657813       68.015792\n",
       "view           48200.108524    63027.898001\n",
       "sqft_above     48290.088862       42.010495\n",
       "sqft_living    56748.836801       83.084210\n",
       "waterfront     63742.899560   715535.170469\n",
       "yr_built      -67643.117413    -2400.669330\n",
       "lat            78375.736932   553505.032276\n",
       "grade          92231.474822    79534.602722"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We should be able to pass this a dataset, then it normalises it. Will also expose functions to normalise further bits\n",
    "# It seems that \"unstandardisation\" isn't really a thing\n",
    "def standardize(features):\n",
    "    #iterate through the features\n",
    "    features = np.array(features)\n",
    "    \n",
    "    #Nice function which copies the shape of features into a new array\n",
    "    scaled = np.empty_like(features)\n",
    "    for i in range(len(features.T)):\n",
    "        mu = features[:,i].mean()\n",
    "        sd = features[:,i].std()\n",
    "\n",
    "        for j in range(len(features[:,i])):\n",
    "            scaled[j,i] = (features[j,i] - mu)/sd\n",
    "            \n",
    "    return scaled\n",
    "\n",
    "stdreg = linear_model.LinearRegression(normalize=False)\n",
    "stdfeatures = standardize(housing_training_features)\n",
    "stdreg.fit(stdfeatures, housing_training_labels)\n",
    "\n",
    "lib_metrics(stdreg, stdfeatures, housing_training_labels)\n",
    "\n",
    "print(\"Without Scaling R^2: \", reg.score(housing_training_features, housing_training_labels))\n",
    "print(\"With Scaling R^2: \", stdreg.score(stdfeatures, housing_training_labels))\n",
    "labs = [label for label in housing_training_features]\n",
    "\n",
    "stdcomp = pd.DataFrame({\"Standardized\" : pd.Series(stdreg.coef_, index=labs), \n",
    "              \"Unstandardized\" : pd.Series(reg.coef_, index=labs)})\n",
    "stdcomp.reindex(stdcomp.loc[:,\"Standardized\"].abs().sort_values(inplace=False).index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly the $R^2$ value, MSE and RSS have remained the same whether or not the data has been normalised. We would expect a difference in convergence time however, when we construct the gradient descent model in Problem 4\n",
    "\n",
    "### (d) \n",
    "Interpret the results in your own words. Which features contribute mostly to the linear regression model? Is the model fitting the data well? How large is the model error?\n",
    "\n",
    "We see that the features with the largest theta values contribute the most to the linear regression. Results were ordered by their absolute value to include negative effects. Several results are unexpected, especially the negative correlation between bedrooms and price. A basic graph below demonstrates this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e392a6c438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD8CAYAAACyyUlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHfJJREFUeJzt3X+QXXWZ5/H3h6ajDY40SHShkxgWs1nB7BDsIrFSZTk4Q4LOQA+rtbAoKYsylgVbWk5lTSyrAKUKrOyMW9Y4TKFkDcoQEWITR5weFrDctQDpGCAGzNKiku6wECY04tALoXn2j/vteLu5596+fXM559z+vKpu9b3PPT++6STnOef7UxGBmZlZK47JuwBmZlZ+TiZmZtYyJxMzM2uZk4mZmbXMycTMzFrmZGJmZi1zMjEzs5Y5mZiZWcucTMzMrGXH5l2AN8rJJ58cS5cuzbsYZmalsmvXruciYmGj7eZNMlm6dCnDw8N5F8PMrFQk/XY227may8zMWuZkYmZmLXMyMTOzljmZmJlZy5xMzMysZfOmN5fZfDG4e4wtQ/s4MD7Bqb09bFy7nIGVfXkXyzqck4nZLJTlAj24e4zNO/YwcXgSgLHxCTbv2ANQyPJa53A1l1kDUxfosfEJgj9coAd3j+VdtNfZMrTvSCKZMnF4ki1D+3Iqkc0XTiZmDZTpAn1gfKKpuNnR4mRi1kCZLtCn9vY0FTc7WhomE0lvlvQzSY9I2ivpmhQ/TdKDkp6Q9F1JC1L8TenzSPp+adWxNqf4Pklrq+LrUmxE0qaqeNPnMDvaynSB3rh2OT3dXdNiPd1dbFy7PKcS2XwxmyeTl4FzI+KPgbOAdZJWA18BvhoRy4DngcvT9pcDz0fEu4Cvpu2QdAZwMXAmsA74O0ldkrqArwPnA2cAl6RtafYcZu1Qpgv0wMo+rrtoBX29PQjo6+3huotWuPHd2q5hb66ICOD36WN3egVwLvCfU3wbcDVwA3Bheg9wO/C3kpTi2yPiZeDXkkaAc9J2IxHxJICk7cCFkh5v9hyprGZH1dSFuAy9uaBS3qKWzTrXrLoGp6eHXcC7qDxF/AoYj4hX0yajwNS/3j5gP0BEvCrpBeBtKf5A1WGr99k/I74q7dPsOZ6bUe4NwAaAJUuWzOaPalaTL9Bm9c2qAT4iJiPiLGARlaeJd9faLP1UxndHK17vHNMDETdGRH9E9C9c2HA6fjMzm6OmenNFxDjwY2A10Ctp6slmEXAgvR8FFgOk708ADlXHZ+yTFX9uDucwM7MczKY310JJvel9D/CnwOPAfcBH0mbrgTvT+53pM+n7e1Nbxk7g4tQT6zRgGfAz4CFgWeq5tYBKI/3OtE+z5zAzsxzMps3kFGBbajc5BrgtIv5R0mPAdknXAruBm9L2NwHfTg3sh6gkByJir6TbgMeAV4ErImISQNKVwBDQBWyNiL3pWJ9v5hxmVp6pX6yzaL7c0Pf394eX7bVON3NuLqh0Y3b3YJsrSbsior/Rdh4Bb9ZByjT1i3UWJxOzDlKmqV+ssziZmHWQMk39Yp3FycSsg5Rp6hfrLF4cy6yDlG3qF+scTiZmHcZTv1geXM1lZmYtczIxM7OWOZmYmVnLnEzMzKxlTiZmZtYyJxMzM2uZk4mZmbXMycTMzFrmZGJmZi1zMjEzs5Y5mZiZWcucTMzMrGVOJmZm1jInEzMza5mTiZmZtczJxMzMWuZkYmZmLXMyMTOzljVMJpIWS7pP0uOS9kr6TIpfLWlM0sPp9aGqfTZLGpG0T9Laqvi6FBuRtKkqfpqkByU9Iem7khak+JvS55H0/dJG5zAzszfebJ5MXgX+KiLeDawGrpB0RvruqxFxVnrdBZC+uxg4E1gH/J2kLkldwNeB84EzgEuqjvOVdKxlwPPA5Sl+OfB8RLwL+GraLvMcc/4tmJlZSxomk4h4OiJ+nt6/CDwO9NXZ5UJge0S8HBG/BkaAc9JrJCKejIhXgO3AhZIEnAvcnvbfBgxUHWtben878MG0fdY5zMwsB021maRqppXAgyl0paRHJW2VdGKK9QH7q3YbTbGs+NuA8Yh4dUZ82rHS9y+k7bOONbO8GyQNSxo+ePBgM39UMzNrwqyTiaS3AHcAn42I3wE3AKcDZwFPA389tWmN3WMO8bkca3og4saI6I+I/oULF9bYxczMjoZZJRNJ3VQSyS0RsQMgIp6JiMmIeA34Bn+oZhoFFlftvgg4UCf+HNAr6dgZ8WnHSt+fAByqcywzM8vBbHpzCbgJeDwi/qYqfkrVZn8J/CK93wlcnHpinQYsA34GPAQsSz23FlBpQN8ZEQHcB3wk7b8euLPqWOvT+48A96bts85hZmY5OLbxJqwBPg7skfRwin2BSm+ss6hUL/0G+BRAROyVdBvwGJWeYFdExCSApCuBIaAL2BoRe9PxPg9sl3QtsJtK8iL9/LakESpPJBc3OofZfPfFwT3c+uB+JiPokrhk1WKuHViRd7Gsw6lyo9/5+vv7Y3h4OO9imLXVFwf38J0Hnnpd/GOrlxQ2oQzuHmPL0D4OjE9wam8PG9cuZ2BlvQ6j9kaStCsi+htt5xHwZh3k1gf3NxXP2+DuMTbv2MPY+AQBjI1PsHnHHgZ3j+VdNGuSk4lZB5nMqGnIiudty9A+Jg5Pr6GeODzJlqF9OZXI5srJxKyDdKlWr/nseN4OjE80FbficjIx6yCXrFrcVDxvp/b2NBW34nIyMesg1w6s4GOrlxx5EumSCt34vnHtcnq6p0+r19Pdxca1y3Mqkc2Ve3OZWa7cm6vYZtubazbjTMzM2mZgZZ+TRwdwNZeZmbXMTyZmHaZsI+BdzdUZnEzMOsjMEfCTEUc+FzGhTA1anBprMjVoEXBCKRlXc5l1kLKNgPegxc7hZGLWQco2At6DFjuHk4lZBynbCHgPWuwcTiZmHaRsI+A9aLFzuAHerINMNbKXpTfXVCO7e3OVn0fAm5lZJo+ANzuKPBbCrD4nE7MGPBbCrDE3wJs14LEQZo05mZg14LEQZo05mZg14LEQZo05mZg14LEQ7TW4e4w119/LaZt+yJrr72Vw91jeRbI5cAO8WQMeC9E+7tzQOZxMzGbBCzi1R73ODf59l0vDai5JiyXdJ+lxSXslfSbFT5J0t6Qn0s8TU1ySviZpRNKjks6uOtb6tP0TktZXxd8raU/a52tSZSKhuZzDrB1cFdMe7tzQOWbTZvIq8FcR8W5gNXCFpDOATcA9EbEMuCd9BjgfWJZeG4AboJIYgKuAVcA5wFVTySFts6Fqv3Up3tQ5zNphqipmbHyC4A9VMU4orXPnhs7RMJlExNMR8fP0/kXgcaAPuBDYljbbBgyk9xcCN0fFA0CvpFOAtcDdEXEoIp4H7gbWpe/eGhH3R2Vul5tnHKuZc5gddR5n0j7u3NA5mmozkbQUWAk8CLwjIp6GSsKR9Pa0WR9QvRLPaIrVi4/WiDOHczw9o7wbqDy5sGTJkmb+qGZHuCqmfdy5oX3e6CmAZp1MJL0FuAP4bET8TtnrI9T6IuYQr1uc2ewTETcCN0JloscGxzSr6dTeHsZqJA5XxRwd7txw9OXRS25W40wkdVNJJLdExI4Ufmaqain9fDbFR4HqxRMWAQcaxBfViM/lHGZHnatirGzyqJqdTW8uATcBj0fE31R9tROY6pG1HrizKn5Z6nG1GnghVVUNAedJOjE1vJ8HDKXvXpS0Op3rshnHauYcZkfdwMo+rrtoBX29PQjo6+3huotW+G7aCiuPqtnZVHOtAT4O7JH0cIp9AbgeuE3S5cBTwEfTd3cBHwJGgJeATwBExCFJXwYeStt9KSIOpfefBr4F9AA/Si+aPYdZu7gqxsokj6pZL45lZtZhZraZQKVqdi5P1F4cy8xsnsqjl5yTiZlZB3qjq2Y9a7CZmbXMycTMzFrmZGJmZi1zMjEzs5Y5mZiZWcucTMzMrGVOJmZm1jInEzMza5mTiZmZtczJxMzMWuZkYmZmLXMyMTOzljmZmJlZy5xMzMysZU4mZmbWMicTMzNrmRfHMjObpcHdY2/o6oVl4mRi1mF8wWuPmeuqj41PsHnHHgD/fnE1l1lHmbrgjY1PEPzhgje4eyzvopXelqF9RxLJlInDk2wZ2pdTiYrFTyZmHaTeBa+od89leZI6MD7RVHy+8ZOJWQcp2wWvTE9Sp/b2NBWfb5xMzDpI2S54Zao62rh2OT3dXdNiPd1dbFy7PKcSFUvDZCJpq6RnJf2iKna1pDFJD6fXh6q+2yxpRNI+SWur4utSbETSpqr4aZIelPSEpO9KWpDib0qfR9L3Sxudw2y+K9sFr0xPUgMr+7juohX09fYgoK+3h+suWlHIKrk8zKbN5FvA3wI3z4h/NSL+W3VA0hnAxcCZwKnA/5T079LXXwf+DBgFHpK0MyIeA76SjrVd0t8DlwM3pJ/PR8S7JF2ctvtPWeeIiOm3N2bz0MDKPoZ/e4hbH9zPZARdEv/xvX2FveD1HtfN8y8drhkvooGVxf1d5q3hk0lE/AQ4NMvjXQhsj4iXI+LXwAhwTnqNRMSTEfEKsB24UJKAc4Hb0/7bgIGqY21L728HPpi2zzqH2bw3uHuMO3aNMRkBwGQEd+waK2QbBMD/O1z7HjArbsXVSpvJlZIeTdVgJ6ZYH7C/apvRFMuKvw0Yj4hXZ8SnHSt9/0LaPutYryNpg6RhScMHDx6c25/SDPji4B5O33wXSzf9kNM338UXB/fkXaSaytQGATBx+LWm4lZcc00mNwCnA2cBTwN/neKqsW3MIT6XY70+GHFjRPRHRP/ChQtrbWLW0BcH9/CdB56adrf/nQeeKmRCGctoa8iKmx0tc0omEfFMRExGxGvAN/hDNdMosLhq00XAgTrx54BeScfOiE87Vvr+BCrVbVnHMmuLWx/c31Q8T12qda+VHc/biRltI1lxK645JRNJp1R9/EtgqqfXTuDi1BPrNGAZ8DPgIWBZ6rm1gEoD+s6ICOA+4CNp//XAnVXHWp/efwS4N22fdQ6ztph6IpltPE9lKivAVX9xJt1d0xNdd5e46i/OzKlENlcNe3NJuhX4AHCypFHgKuADks6iUr30G+BTABGxV9JtwGPAq8AVU72sJF0JDAFdwNaI2JtO8Xlgu6Rrgd3ATSl+E/BtSSNUnkgubnQOs3bokmpejIt4t9/X21OzSquvoONMpnpGlWEEvNWnKOgdy9HW398fw8PDeRfDSmiqzWSmj61ewrUDK3IoUbYyldXKQdKuiOhvtJ1HwJs1cO3ACj62esmRJ5EuqbAX5x27RpuKmx0tnujRbBb633kS9/3yIAfGJ/g3J7yZ/neelHeRanopo0ttVrwIyjLRo9XnZGLWgNexaB//bjuHq7nMGijbQMAy8e+2c/jJxHJTluoNDwRsH/9uO4efTCwXZVrHIqsDcPE6BpdvEGDZBllaNicTy0WZqjeyOs8XsVN92QYBlm2QpWVzNZflokzrWJRJ2QYB9nQfU3NSx55u3+eWjf/GLBdlWhGwTNVcZfPyq7W7LGfFrbicTCwXZVoR8NLVS5qK52lw9xgbb39kWlvUxtsfKWRbFMBrGbVZWXErLicTy0WZlkAt0wj4a36wl8OT06/EhyeDa36wN2OPfLkBvnO4zcRyU6YlUMsyAr7WErj14nm7ZNXimnOJXbJqcY2trcicTMwa8Cjt9pl6uqtes/6SVYsL+dRn9TmZmDVQrxuzk0nrrh1Y4eTRAdxmYtaAuzGbNeZkYtZAmboxm+XFycSsgY1rl9ccVV7EbsxZY/08BtDazf/EzGZj5riHgo6DyFq2pMDLmViHcAN8A2WZ2dbaZ8vQPg7PGEV3+LVwA/xRcuk37uenvzp05POa00/ilk++L8cS2Vz4yaSOMs1sW0aDu8dYc/29nLbph6y5/t7C/l49TXr7zEwkAD/91SEu/cb9OZXI5spPJnW4S2j7eOxGe0hQa8Ldog4on5lIGsXz5pqKbH4yqcNdQtunTFPQl0nWzO2e0b11rqmoz8mkDncJbZ8yJeqsu/oi3u2XbXGsMvENUH1OJnWUaWbbsilTos76T1LE/zxlezJZ9vbjm4rnqUw3QHlo+P9B0lZJz0r6RVXsJEl3S3oi/TwxxSXpa5JGJD0q6eyqfdan7Z+QtL4q/l5Je9I+X5Mq93tzOcfRVqaZbcumTIl6MuNCnBXP0wsTtSd0zIrn7eCLrzQVz1OZboDyMJubq28B62bENgH3RMQy4J70GeB8YFl6bQBugEpiAK4CVgHnAFdNJYe0zYaq/dbN5RztMrCyj59uOpdfX/9hfrrpXCeSo8SJuj2yVigs6sqF4xlJLiuepzLdAOWhYW+uiPiJpKUzwhcCH0jvtwE/Bj6f4jdHRAAPSOqVdEra9u6IOAQg6W5gnaQfA2+NiPtT/GZgAPhRs+eIiKeb+6Nb3so0BX1ZvJQxOjErbrNXtiWR32hz7Rr8jqmLd0Q8LentKd4H7K/abjTF6sVHa8Tnco7XJRNJG6g8vbBkSfFWxTOb77qPqT06v6APUr4BquNo/5XV6t8Sc4jP5RyvD0bcGBH9EdG/cOHCBoc1q+24jCtbVtxmL2updy8BXz5z/d/wTKq+Iv18NsVHgeol0hYBBxrEF9WIz+UcZm3hqqP2ybpzLGDfBmtgrslkJzDVI2s9cGdV/LLU42o18EKqqhoCzpN0Ymp4Pw8YSt+9KGl16sV12YxjNXMOMzPLScM2E0m3UmkIP1nSKJVeWdcDt0m6HHgK+Gja/C7gQ8AI8BLwCYCIOCTpy8BDabsvTTXGA5+m0mOsh0rD+49SvKlzmJlZfmbTm+uSjK8+WGPbAK7IOM5WYGuN+DDwnhrxf2n2HGZmlg+3IJqZWcucTMwsN8cv6GoqbsXlZGJmuenuqn0JyopbcflvzMxyU7a5xCybk4mZ5ebNGQM/s+JWXF5p0XLjVetsImPgZ1bcisvJxHLhZXvNOoufJS0XXrXOrLP4ycRy4VXrrIxcNZvNTyaWC69aZwC9PbXXps+K52lw9xgbv/cIY+MTBJWq2Y3fe4TB3WN5F60QnEwsF0vfVjtpZMWtM119wZlNxfN09c69HH5t+nzGh18Lrt65N6cSFYuTieXigSefbypunWn4t4eaiuepTEsM58HJxHIxGbVXrMiKW2e65YGnmopbcTmZmFluyrQ41onH1W7HyYrPN04mZmaz8OH/cEpT8fnGycRyITUXN8vbDx+tvaBrVny+cTKxXGQ1jbjJxIrq+ZdqN7RnxecbJxMzM2uZk4mZ2SyUaYBlHpxMzMxm4eoLzqT7mOmNet3HqJADLPPgubnMLDddUs2xRV0F7IkxNQeX5+aqzcnEzHJTtsGrAyv7nDwyuJrLzHLTk7GiYlbcist/Y2aWG6+02DlaSiaSfiNpj6SHJQ2n2EmS7pb0RPp5YopL0tckjUh6VNLZVcdZn7Z/QtL6qvh70/FH0r6qdw4zM8vH0Xgy+ZOIOCsi+tPnTcA9EbEMuCd9BjgfWJZeG4AboJIYgKuAVcA5wFVVyeGGtO3UfusanMPMzHLQjmquC4Ft6f02YKAqfnNUPAD0SjoFWAvcHRGHIuJ54G5gXfrurRFxf0QEcPOMY9U6h5lZ2wzuHmPN9fdy2qYfsub6e70wVpVWk0kA/yxpl6QNKfaOiHgaIP18e4r3Afur9h1NsXrx0RrxeueYRtIGScOShg8ePDjHP6KZWSWRfO62h6ettPi52x52QklaTSZrIuJsKlVYV0h6f51ta3UcjznEZy0iboyI/ojoX7hwYTO7mplN84UdjzJjoUVei0rcWkwmEXEg/XwW+D6VNo9nUhUV6eezafNRYHHV7ouAAw3ii2rEqXMOM7O2eCmjh1lWfL6ZczKRdLykP5p6D5wH/ALYCUz1yFoP3Jne7wQuS726VgMvpCqqIeA8SSemhvfzgKH03YuSVqdeXJfNOFatc5iZWQ5aGQH/DuD7qbfuscA/RMQ/SXoIuE3S5cBTwEfT9ncBHwJGgJeATwBExCFJXwYeStt9KSKmFoD+NPAtoAf4UXoBXJ9xDjOztpBqL5FQwJlfcjHnZBIRTwJ/XCP+L8AHa8QDuCLjWFuBrTXiw8B7ZnsOM7N2uXTVEr5TY236S1ctyaE0xeO5uTrI4O4xT0Jn1ibXDqwA4NYH9zMZQZfEJasWH4nPd04mHWJw9xgbb3+Ew5OV5/Cx8Qk23v4IgBOK2VFy7cAKJ48MnpurQ1zzg71HEsmUw5PBNT/Ym1OJzGw+8ZNJh/D61Gbt56rkbE4mZmazMLh7jM079jBxeBKoVCVv3rEHcFUyuJqrY3hdCLP22jK070gimTJxeJItQ/tyKlGx+ErTId7c3dVU3Myac2B8oqn4fONk0iHGM9pGsuJm1pwTerqbis83TiYd4tTenqbiZtacrJHuHgFf4WTSIf7k39eeFTkrbmbN8dN/fU4mHeK+X9ZeryUrbmbN8dN/fU4mHcKNg1ZGWTVERaw52rh2OT0zOrT0dHexce3ynEpULB5n0iFO6OlmfOL1j9tuHLQiW3DsMbz86uvXA1lwbPHuc6fGknjQYm1OJh3CjYNWRrUSSb143gZW9jl5ZChe+rc5ceOgmeXJyaRD9B5XuzorK25WBL0Z1bBZcSsuJ5MOUWsFuHpxsyK4+oIz6T5mel1s9zHi6gvOzKlENlduM+kQL9RofK8XNysCN2p3DieTDnFqbw9jNboBF7UP/PELuvjXVyZrxm3u1px+Ej/91aGa8aJyo3ZncDVXh9i4djndXTOqC7pU2D7wL9VIJPXiecq6EBfxAn3LJ9/3unKtOf0kbvnk+3Iqkc0XfjLpJDPbRwrcXlKmJ6lbPvk+Lv3G/dPu+It8gS5quayzOZl0iC1D+zj82oxle18LtgztK2QVwsa1y6ctNATFHk3sC7RZfU4mHaJs06m44dWssziZdIgyVRtNccOrWecodQO8pHWS9kkakbQp7/LkyZPQmVmeSvtkIqkL+DrwZ8Ao8JCknRHxWL4ly4erjcwsT6VNJsA5wEhEPAkgaTtwITAvkwm42sjM8lPmaq4+YH/V59EUO0LSBknDkoYPHvQiUWZm7VLmZFJrcvVpfWMj4saI6I+I/oULvXytmVm7lDmZjAKLqz4vAg7kVBYzs3mtzMnkIWCZpNMkLQAuBnbmXCYzs3mptA3wEfGqpCuBIaAL2BoRe3MulpnZvKSYJwteSDoI/LaFQ5wMPHeUitNuZSorlKu8Lmv7lKm886ms74yIho3O8yaZtErScET0512O2ShTWaFc5XVZ26dM5XVZX6/MbSZmZlYQTiZmZtYyJ5PZuzHvAjShTGWFcpXXZW2fMpXXZZ3BbSZmZtYyP5mYmVnLnEwaKNM095K2SnpW0i/yLksjkhZLuk/S45L2SvpM3mWqR9KbJf1M0iOpvNfkXaZGJHVJ2i3pH/MuSz2SfiNpj6SHJQ3nXZ5GJPVKul3SL9O/30IuwylpefqdTr1+J+mzbTufq7mypWnu/w9V09wDlxR1mntJ7wd+D9wcEe/Juzz1SDoFOCUifi7pj4BdwECBf7cCjo+I30vqBv438JmIeCDnomWS9DmgH3hrRPx53uXJIuk3QH9ElGLchqRtwP+KiG+m2TeOi4jxvMtVT7qWjQGrIqKV8XaZ/GRS35Fp7iPiFWBqmvtCioifAIfyLsdsRMTTEfHz9P5F4HFmzPpcJFHx+/SxO70KeycmaRHwYeCbeZelk0h6K/B+4CaAiHil6Ikk+SDwq3YlEnAyaaThNPfWOklLgZXAg/mWpL5UbfQw8Cxwd0QUubz/HfivwGt5F2QWAvhnSbskbci7MA38W+Ag8D9SFeI3JR2fd6Fm4WLg1naewMmkvobT3FtrJL0FuAP4bET8Lu/y1BMRkxFxFpUZqs+RVMiqREl/DjwbEbvyLsssrYmIs4HzgStSdW1RHQucDdwQESuBfwWK3pa6ALgA+F47z+NkUp+nuW+j1PZwB3BLROzIuzyzlao1fgysy7koWdYAF6S2iO3AuZK+k2+RskXEgfTzWeD7VKqXi2oUGK16Kr2dSnIpsvOBn0fEM+08iZNJfZ7mvk1Sg/ZNwOMR8Td5l6cRSQsl9ab3PcCfAr/Mt1S1RcTmiFgUEUup/Ju9NyI+lnOxapJ0fOqAQaouOg8obG/EiPi/wH5Jy1PogxR/qfBLaHMVF5R4Cvo3QtmmuZd0K/AB4GRJo8BVEXFTvqXKtAb4OLAntUMAfCEi7sqxTPWcAmxLvWKOAW6LiEJ3uS2JdwDfr9xbcCzwDxHxT/kWqaH/AtySbjCfBD6Rc3kySTqOSm/UT7X9XO4abGZmrXI1l5mZtczJxMzMWuZkYmZmLXMyMTOzljmZmJlZy5xMzMysZU4mZmbWMicTMzNr2f8Hj896W64MaqMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot housing.loc[:,\"bedrooms\"],housing.loc[:,\"price\"]\n",
    "import matplotlib.pyplot as plt\n",
    "display(plt.scatter(housing.loc[:,\"bedrooms\"], housing.loc[:,\"price\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a positive correlation before we account for all other features\n",
    "\n",
    "The model is fitting the data reasonably well, $R^2$ shows that 72.65% of the variation in the data can be explained by the multiple linear model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 [Closed form solution of linear regression]\n",
    "\n",
    "\n",
    "In this problem, you will implement your own linear regression model, using the closed-form solution we derived in class. You will also compare your model with the one trained with the package.\n",
    "\n",
    "\n",
    "1. Implement simple linear regression and train a model for one feature (sqft\\_living) using the training set. Write code to predict a response for a new single-dimensional data point in the testing set.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\theta_0 = -32304.6547, \\theta_1 = 269.4621$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$\\text{Predicted}=388056.15 \\space ft^2\\\\ \\text{Actual}= 270000.0\\space ft^2$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$RSS = 57947526161288.3594 \\\\ MSE = 57947526161.2884 \\\\ R^2 = 0.4967$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Lin:\n",
    "    \"\"\"Fit a linear model to some datapoints in 2 dimensions\"\"\"\n",
    "    def __init__(self):\n",
    "        self.theta = np.ones(2)\n",
    "        self._rss = 0\n",
    "        self.n = 0\n",
    "        self._tss = 0\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        \"\"\"Takes X Feature numpy 1d array, y Label numpy 1d array\"\"\"\n",
    "        \n",
    "        self.n = X.shape[0]\n",
    "        \n",
    "        x_m = np.mean(X)\n",
    "        y_m = np.mean(y)\n",
    "        \n",
    "        # for each training data point in x, and corresponding label y\n",
    "        # calculate 2 separate values, using this formula and a mean of each\n",
    "        a = b = 0\n",
    "        for i in range(self.n):\n",
    "            diffx = X[i]-x_m\n",
    "            a += (diffx)*(y[i]-y_m)\n",
    "            b += (diffx)**2\n",
    "            \n",
    "        self.theta[1] = a/b\n",
    "        self.theta[0] = y_m-self.theta[1]*x_m\n",
    "        \n",
    "        for i in range(self.n):\n",
    "            self._rss += (y[i] - self.predict(X[i]))**2\n",
    "            self._tss += (y[i] - y_m)**2\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def rss(self):\n",
    "        return self._rss\n",
    "    \n",
    "    def mse(self):\n",
    "        return (self._rss / self.n)\n",
    "    \n",
    "    def r2(self):\n",
    "        return 1-(self._rss/self._tss)\n",
    "    \n",
    "    def coef(self):\n",
    "        \"\"\"Return the coefficients vector\"\"\"\n",
    "        return self.theta\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.theta[0] + x*self.theta[1]\n",
    "\n",
    "mod = Lin()\n",
    "\n",
    "housing_training_features\n",
    "mod.fit(housing.loc[:,'sqft_living'], housing.loc[:,'price'])\n",
    "\n",
    "thetas = mod.coef()\n",
    "display(Math(\"\\\\theta_0 = {0:.4f}, \\\\theta_1 = {1:.4f}\".format(thetas[0], thetas[1])))\n",
    "\n",
    "predict = housing_test.loc[1,'sqft_living']\n",
    "model = mod.predict(predict)\n",
    "actual = housing_test.loc[1,'price']\n",
    "\n",
    "display(Math(\"\\\\text{Predicted}=\" + \n",
    "             str(round(model, 2)) + \n",
    "             \" \\\\space ft^2\\\\\\\\ \\\\text{Actual}= \" + \n",
    "             str(round(actual, 2)) + \n",
    "             \"\\\\space ft^2\"\n",
    "            ))\n",
    "\n",
    "display(Math(\"RSS = {:.4f} \\\\\\\\ MSE = {:.4f} \\\\\\\\ R^2 = {:.4f}\".format(mod.rss(), mod.mse(), mod.r2())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement multiple linear regression using matrix operations and train a model on the training set. Write code to predict a response for a new multi-dimensional data point in the testing set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\text{Predicted}=689731.07 \\space ft^2\\\\ \\text{Actual}= 700000.0\\space ft^2$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$RSS = 31862677597299.113 \\\\ MSE = 31862677597.299114 \\\\ R^2 = 0.7233$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Multi_lin:\n",
    "    # has a coeficients property\n",
    "    # has a fit method\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.theta = np.ones((1,))\n",
    "        self._rss = 0\n",
    "        self.n = 0\n",
    "        self._tss = 0\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        #We need to add a column of ones to x to allow the intercept to work\n",
    "        \n",
    "        self.n = X.shape[0]\n",
    "        intercept = np.ones(len(X))\n",
    " \n",
    "        X = np.column_stack((intercept, X))\n",
    "        \n",
    "        y_m = y.mean()\n",
    "        #use theta\n",
    "        self.theta = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "        self._calc_rss(X, y, y_m)\n",
    "        return self\n",
    "    \n",
    "    def coef(self):\n",
    "        return self.theta[1:]\n",
    "    \n",
    "    def intercept(self):\n",
    "        return self.theta[0]\n",
    "    \n",
    "    def _calc_rss(self, X, y, y_m):\n",
    "        #we have to strip off all of the leading 1's\n",
    "        for i in range(self.n):\n",
    "            self._rss += (y[i] - self.predict(X[i,1:]))**2\n",
    "            self._tss += (y[i] - y_m)**2\n",
    "            \n",
    "    def mse(self):\n",
    "        return (self._rss / self.n)\n",
    "        \n",
    "    def rss(self):\n",
    "        return self._rss\n",
    "    \n",
    "    def r2(self):\n",
    "        return 1-(self._rss/self._tss)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.theta.T.dot(np.insert(x, 0, 1))\n",
    "    \n",
    "    \n",
    "mult = Multi_lin()\n",
    "\n",
    "# Prediction of price using new multidimensional data point\n",
    "\n",
    "mult.fit(np.array(housing_training_features), housing_training_labels)\n",
    "model = mult.predict(np.array(housing_testing_features.loc[0,:]))\n",
    "actual = housing_testing_labels[0]\n",
    "\n",
    "display(Math(\"\\\\text{Predicted}=\" + \n",
    "             str(round(model, 2)) + \n",
    "             \" \\\\space ft^2\\\\\\\\ \\\\text{Actual}= \" + \n",
    "             str(round(actual, 2)) + \n",
    "             \"\\\\space ft^2\"\n",
    "            ))\n",
    "\n",
    "display(Math(\"RSS = {0} \\\\\\\\ MSE = {1} \\\\\\\\ R^2 = {2:.4f}\".format(mult.rss(), mult.mse() , mult.r2())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compare the models given by your implementation with those trained in Problem 2 by the R or Python packages. Report the MSE, RSE, and $R^2$ metrics for the models you implemented. Compare the coefficients output by your model with the ones computed by the package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple linear regression\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$RSS = 57947526161288.3594 \\\\ MSE = 57947526161.2884 \\\\ R^2 = 0.4967$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple linear regression library:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$R^2 = 0.4967$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$MSE=57947526161$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$RSS=57947526161288$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple linear regression: \n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$RSS = 31862677597299.1133 \\\\ MSE = 31862677597.2991 \\\\ R^2 = 0.7233$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple linear regression library\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$R^2 = 0.7265$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$MSE=31486167776$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$RSS=31486167775795$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>multiple_code</th>\n",
       "      <th>multiple_library</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-470.805669</td>\n",
       "      <td>-2.308890e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-15737.805001</td>\n",
       "      <td>-1.470428e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26264.450129</td>\n",
       "      <td>2.568778e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.504985</td>\n",
       "      <td>8.308421e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.350240</td>\n",
       "      <td>3.759298e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23344.816106</td>\n",
       "      <td>1.555558e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>725344.412572</td>\n",
       "      <td>7.155352e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65223.592066</td>\n",
       "      <td>6.302790e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16620.915477</td>\n",
       "      <td>1.881640e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>85550.566113</td>\n",
       "      <td>7.953460e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.327279</td>\n",
       "      <td>4.201050e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48.177874</td>\n",
       "      <td>4.107372e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2896.687815</td>\n",
       "      <td>-2.400669e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>39.137433</td>\n",
       "      <td>4.368294e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>508933.461024</td>\n",
       "      <td>5.535050e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>156340.326253</td>\n",
       "      <td>-7.424027e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>58.171586</td>\n",
       "      <td>6.801579e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.639549</td>\n",
       "      <td>-5.155276e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    multiple_code  multiple_library\n",
       "0     -470.805669     -2.308890e+07\n",
       "1   -15737.805001     -1.470428e+04\n",
       "2    26264.450129      2.568778e+04\n",
       "3       84.504985      8.308421e+01\n",
       "4        0.350240      3.759298e-01\n",
       "5    23344.816106      1.555558e+04\n",
       "6   725344.412572      7.155352e+05\n",
       "7    65223.592066      6.302790e+04\n",
       "8    16620.915477      1.881640e+04\n",
       "9    85550.566113      7.953460e+04\n",
       "10      36.327279      4.201050e+01\n",
       "11      48.177874      4.107372e+01\n",
       "12   -2896.687815     -2.400669e+03\n",
       "13      39.137433      4.368294e+01\n",
       "14  508933.461024      5.535050e+05\n",
       "15  156340.326253     -7.424027e+03\n",
       "16      58.171586      6.801579e+01\n",
       "17      -0.639549     -5.155276e-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Linear model trained:\n",
    "print(\"Simple linear regression\")\n",
    "display(Math(\"RSS = {:.4f} \\\\\\\\ MSE = {:.4f} \\\\\\\\ R^2 = {:.4f}\".format(mod.rss(), mod.mse(), mod.r2())))\n",
    "\n",
    "#libaray simple linear regression\n",
    "simplereg = linear_model.LinearRegression()\n",
    "features = np.array(housing_training_features.loc[:,\"sqft_living\"])[:, np.newaxis]\n",
    "labels = np.array(housing_training_labels)[:, np.newaxis]\n",
    "simplereg.fit(features, housing_training_labels)\n",
    "\n",
    "\n",
    "print(\"Simple linear regression library:\")\n",
    "display(Math(\"R^2 = {0:.4f}\".format(simplereg.score(features, housing_training_labels))))\n",
    "simpleregmse = metrics.mean_squared_error(labels, simplereg.predict(features))\n",
    "display(Math(\"MSE={0:.0f}\".format(simpleregmse)))\n",
    "\n",
    "simpleregrss = simpleregmse*len(housing_training_labels)\n",
    "display(Math(\"RSS={0:.0f}\".format(simpleregrss)))\n",
    "\n",
    "#Multiple linear model trained:\n",
    "print(\"Multiple linear regression: \")\n",
    "display(Math(\"RSS = {0:.4f} \\\\\\\\ MSE = {1:.4f} \\\\\\\\ R^2 = {2:.4f}\".format(mult.rss(), mult.mse(), mult.r2())))\n",
    "\n",
    "print(\"Multiple linear regression library\")\n",
    "lib_metrics(reg, housing_training_features, housing_training_labels)\n",
    "\n",
    "output = pd.DataFrame()\n",
    "# This mult.coef is 17 long. This is equal to the number of predictors\n",
    "#however we also need an intercept --- Where is the intercept?\n",
    "output[\"multiple_code\"] = np.insert(mult.coef(), 0, mult.intercept())\n",
    "\n",
    "output[\"multiple_library\"] = np.insert(reg.coef_, 0, reg.intercept_)\n",
    "\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 [Gradient Descent]\n",
    "\n",
    "In this problem, you will implement your own gradient descent algorithm and apply it to linear regression. Use the scaled dataset.\n",
    "\n",
    "(a) Write code for gradient descent for training linear regression using the algorithm from class.\n",
    "\n",
    "(b) Vary the value of the learning rate (5 different values) and the number of iterations (5 different values)) and report the value of $\\theta$ for each of the 25 combinations, as well as the MSE metric on the training set. Report the MSE on the testing set.\n",
    "\n",
    "(c) Tune your implementation to obtain results close to those obtained with the package. Write some observations: How does the objective change with different learning rates; how many iterations are needed, etc.\n",
    "\n",
    "(d) **Extra credit - 10 points** You will get extra credit if your GD implementation of linear regression achieves MSE very close to the least-square solution given by the package.\n",
    "\n",
    "(e) **Extra credit - 10 points** You will extra credit if your GD implementation of linear regression can run on the entire ''kc\\_house\\_data.csv'' dataset efficiently. Report the running time of your training algorithm for the entire dataset and compare that with the running time of the package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0, 0)</th>\n",
       "      <th>(0, 1)</th>\n",
       "      <th>(0, 2)</th>\n",
       "      <th>(0, 3)</th>\n",
       "      <th>(0, 4)</th>\n",
       "      <th>(1, 0)</th>\n",
       "      <th>(1, 1)</th>\n",
       "      <th>(1, 2)</th>\n",
       "      <th>(1, 3)</th>\n",
       "      <th>(1, 4)</th>\n",
       "      <th>...</th>\n",
       "      <th>(3, 0)</th>\n",
       "      <th>(3, 1)</th>\n",
       "      <th>(3, 2)</th>\n",
       "      <th>(3, 3)</th>\n",
       "      <th>(3, 4)</th>\n",
       "      <th>(4, 0)</th>\n",
       "      <th>(4, 1)</th>\n",
       "      <th>(4, 2)</th>\n",
       "      <th>(4, 3)</th>\n",
       "      <th>(4, 4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.156251e+05</td>\n",
       "      <td>2.055607e+05</td>\n",
       "      <td>2.755146e+05</td>\n",
       "      <td>3.299262e+05</td>\n",
       "      <td>3.722487e+05</td>\n",
       "      <td>1.156251e+05</td>\n",
       "      <td>2.055607e+05</td>\n",
       "      <td>2.755146e+05</td>\n",
       "      <td>3.299262e+05</td>\n",
       "      <td>3.722487e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.156251e+05</td>\n",
       "      <td>2.055607e+05</td>\n",
       "      <td>2.755146e+05</td>\n",
       "      <td>3.299262e+05</td>\n",
       "      <td>3.722487e+05</td>\n",
       "      <td>1.156251e+05</td>\n",
       "      <td>2.055607e+05</td>\n",
       "      <td>2.755146e+05</td>\n",
       "      <td>3.299262e+05</td>\n",
       "      <td>3.722487e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.652948e-11</td>\n",
       "      <td>-4.712960e-11</td>\n",
       "      <td>-6.316745e-11</td>\n",
       "      <td>-7.564737e-11</td>\n",
       "      <td>-8.534061e-11</td>\n",
       "      <td>-2.652948e-11</td>\n",
       "      <td>-4.712960e-11</td>\n",
       "      <td>-6.316745e-11</td>\n",
       "      <td>-7.564737e-11</td>\n",
       "      <td>-8.534061e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.652948e-11</td>\n",
       "      <td>-4.712960e-11</td>\n",
       "      <td>-6.316745e-11</td>\n",
       "      <td>-7.564737e-11</td>\n",
       "      <td>-8.534061e-11</td>\n",
       "      <td>-2.652948e-11</td>\n",
       "      <td>-4.712960e-11</td>\n",
       "      <td>-6.316745e-11</td>\n",
       "      <td>-7.564737e-11</td>\n",
       "      <td>-8.534061e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.106073e-12</td>\n",
       "      <td>1.438429e-11</td>\n",
       "      <td>1.926894e-11</td>\n",
       "      <td>2.309931e-11</td>\n",
       "      <td>2.609025e-11</td>\n",
       "      <td>8.106073e-12</td>\n",
       "      <td>1.438429e-11</td>\n",
       "      <td>1.926894e-11</td>\n",
       "      <td>2.309931e-11</td>\n",
       "      <td>2.609025e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>8.106073e-12</td>\n",
       "      <td>1.438429e-11</td>\n",
       "      <td>1.926894e-11</td>\n",
       "      <td>2.309931e-11</td>\n",
       "      <td>2.609025e-11</td>\n",
       "      <td>8.106073e-12</td>\n",
       "      <td>1.438429e-11</td>\n",
       "      <td>1.926894e-11</td>\n",
       "      <td>2.309931e-11</td>\n",
       "      <td>2.609025e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.105025e-11</td>\n",
       "      <td>1.963967e-11</td>\n",
       "      <td>2.632662e-11</td>\n",
       "      <td>3.152202e-11</td>\n",
       "      <td>3.557273e-11</td>\n",
       "      <td>1.105025e-11</td>\n",
       "      <td>1.963967e-11</td>\n",
       "      <td>2.632662e-11</td>\n",
       "      <td>3.152202e-11</td>\n",
       "      <td>3.557273e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.105025e-11</td>\n",
       "      <td>1.963967e-11</td>\n",
       "      <td>2.632662e-11</td>\n",
       "      <td>3.152202e-11</td>\n",
       "      <td>3.557273e-11</td>\n",
       "      <td>1.105025e-11</td>\n",
       "      <td>1.963967e-11</td>\n",
       "      <td>2.632662e-11</td>\n",
       "      <td>3.152202e-11</td>\n",
       "      <td>3.557273e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.133934e-12</td>\n",
       "      <td>7.346247e-12</td>\n",
       "      <td>9.846990e-12</td>\n",
       "      <td>1.179033e-11</td>\n",
       "      <td>1.330736e-11</td>\n",
       "      <td>4.133934e-12</td>\n",
       "      <td>7.346247e-12</td>\n",
       "      <td>9.846990e-12</td>\n",
       "      <td>1.179033e-11</td>\n",
       "      <td>1.330736e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>4.133934e-12</td>\n",
       "      <td>7.346247e-12</td>\n",
       "      <td>9.846990e-12</td>\n",
       "      <td>1.179033e-11</td>\n",
       "      <td>1.330736e-11</td>\n",
       "      <td>4.133934e-12</td>\n",
       "      <td>7.346247e-12</td>\n",
       "      <td>9.846990e-12</td>\n",
       "      <td>1.179033e-11</td>\n",
       "      <td>1.330736e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.791923e-11</td>\n",
       "      <td>4.965393e-11</td>\n",
       "      <td>6.652314e-11</td>\n",
       "      <td>7.965457e-11</td>\n",
       "      <td>8.985439e-11</td>\n",
       "      <td>2.791923e-11</td>\n",
       "      <td>4.965393e-11</td>\n",
       "      <td>6.652314e-11</td>\n",
       "      <td>7.965457e-11</td>\n",
       "      <td>8.985439e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>2.791923e-11</td>\n",
       "      <td>4.965393e-11</td>\n",
       "      <td>6.652314e-11</td>\n",
       "      <td>7.965457e-11</td>\n",
       "      <td>8.985439e-11</td>\n",
       "      <td>2.791923e-11</td>\n",
       "      <td>4.965393e-11</td>\n",
       "      <td>6.652314e-11</td>\n",
       "      <td>7.965457e-11</td>\n",
       "      <td>8.985439e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.911601e-13</td>\n",
       "      <td>6.986363e-13</td>\n",
       "      <td>9.333872e-13</td>\n",
       "      <td>1.115161e-12</td>\n",
       "      <td>1.286851e-12</td>\n",
       "      <td>3.911601e-13</td>\n",
       "      <td>6.986363e-13</td>\n",
       "      <td>9.333872e-13</td>\n",
       "      <td>1.115161e-12</td>\n",
       "      <td>1.286851e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>3.911601e-13</td>\n",
       "      <td>6.986363e-13</td>\n",
       "      <td>9.333872e-13</td>\n",
       "      <td>1.115161e-12</td>\n",
       "      <td>1.286851e-12</td>\n",
       "      <td>3.911601e-13</td>\n",
       "      <td>6.986363e-13</td>\n",
       "      <td>9.333872e-13</td>\n",
       "      <td>1.115161e-12</td>\n",
       "      <td>1.286851e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.168265e-12</td>\n",
       "      <td>2.102960e-12</td>\n",
       "      <td>2.845087e-12</td>\n",
       "      <td>3.409722e-12</td>\n",
       "      <td>3.868910e-12</td>\n",
       "      <td>1.168265e-12</td>\n",
       "      <td>2.102960e-12</td>\n",
       "      <td>2.845087e-12</td>\n",
       "      <td>3.409722e-12</td>\n",
       "      <td>3.868910e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.168265e-12</td>\n",
       "      <td>2.102960e-12</td>\n",
       "      <td>2.845087e-12</td>\n",
       "      <td>3.409722e-12</td>\n",
       "      <td>3.868910e-12</td>\n",
       "      <td>1.168265e-12</td>\n",
       "      <td>2.102960e-12</td>\n",
       "      <td>2.845087e-12</td>\n",
       "      <td>3.409722e-12</td>\n",
       "      <td>3.868910e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.455376e-12</td>\n",
       "      <td>1.681003e-11</td>\n",
       "      <td>2.259167e-11</td>\n",
       "      <td>2.709936e-11</td>\n",
       "      <td>3.053029e-11</td>\n",
       "      <td>9.455376e-12</td>\n",
       "      <td>1.681003e-11</td>\n",
       "      <td>2.259167e-11</td>\n",
       "      <td>2.709936e-11</td>\n",
       "      <td>3.053029e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>9.455376e-12</td>\n",
       "      <td>1.681003e-11</td>\n",
       "      <td>2.259167e-11</td>\n",
       "      <td>2.709936e-11</td>\n",
       "      <td>3.053029e-11</td>\n",
       "      <td>9.455376e-12</td>\n",
       "      <td>1.681003e-11</td>\n",
       "      <td>2.259167e-11</td>\n",
       "      <td>2.709936e-11</td>\n",
       "      <td>3.053029e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.822633e-12</td>\n",
       "      <td>1.568641e-11</td>\n",
       "      <td>2.103760e-11</td>\n",
       "      <td>2.520139e-11</td>\n",
       "      <td>2.845774e-11</td>\n",
       "      <td>8.822633e-12</td>\n",
       "      <td>1.568641e-11</td>\n",
       "      <td>2.103760e-11</td>\n",
       "      <td>2.520139e-11</td>\n",
       "      <td>2.845774e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>8.822633e-12</td>\n",
       "      <td>1.568641e-11</td>\n",
       "      <td>2.103760e-11</td>\n",
       "      <td>2.520139e-11</td>\n",
       "      <td>2.845774e-11</td>\n",
       "      <td>8.822633e-12</td>\n",
       "      <td>1.568641e-11</td>\n",
       "      <td>2.103760e-11</td>\n",
       "      <td>2.520139e-11</td>\n",
       "      <td>2.845774e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.233483e-11</td>\n",
       "      <td>-2.192964e-11</td>\n",
       "      <td>-2.939170e-11</td>\n",
       "      <td>-3.519259e-11</td>\n",
       "      <td>-3.970371e-11</td>\n",
       "      <td>-1.233483e-11</td>\n",
       "      <td>-2.192964e-11</td>\n",
       "      <td>-2.939170e-11</td>\n",
       "      <td>-3.519259e-11</td>\n",
       "      <td>-3.970371e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.233483e-11</td>\n",
       "      <td>-2.192964e-11</td>\n",
       "      <td>-2.939170e-11</td>\n",
       "      <td>-3.519259e-11</td>\n",
       "      <td>-3.970371e-11</td>\n",
       "      <td>-1.233483e-11</td>\n",
       "      <td>-2.192964e-11</td>\n",
       "      <td>-2.939170e-11</td>\n",
       "      <td>-3.519259e-11</td>\n",
       "      <td>-3.970371e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.418991e-12</td>\n",
       "      <td>-2.507512e-12</td>\n",
       "      <td>-3.384340e-12</td>\n",
       "      <td>-4.072562e-12</td>\n",
       "      <td>-4.609681e-12</td>\n",
       "      <td>-1.418991e-12</td>\n",
       "      <td>-2.507512e-12</td>\n",
       "      <td>-3.384340e-12</td>\n",
       "      <td>-4.072562e-12</td>\n",
       "      <td>-4.609681e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.418991e-12</td>\n",
       "      <td>-2.507512e-12</td>\n",
       "      <td>-3.384340e-12</td>\n",
       "      <td>-4.072562e-12</td>\n",
       "      <td>-4.609681e-12</td>\n",
       "      <td>-1.418991e-12</td>\n",
       "      <td>-2.507512e-12</td>\n",
       "      <td>-3.384340e-12</td>\n",
       "      <td>-4.072562e-12</td>\n",
       "      <td>-4.609681e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.915399e-11</td>\n",
       "      <td>1.584820e-10</td>\n",
       "      <td>2.124111e-10</td>\n",
       "      <td>2.543671e-10</td>\n",
       "      <td>2.869910e-10</td>\n",
       "      <td>8.915399e-11</td>\n",
       "      <td>1.584820e-10</td>\n",
       "      <td>2.124111e-10</td>\n",
       "      <td>2.543671e-10</td>\n",
       "      <td>2.869910e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>8.915399e-11</td>\n",
       "      <td>1.584820e-10</td>\n",
       "      <td>2.124111e-10</td>\n",
       "      <td>2.543671e-10</td>\n",
       "      <td>2.869910e-10</td>\n",
       "      <td>8.915399e-11</td>\n",
       "      <td>1.584820e-10</td>\n",
       "      <td>2.124111e-10</td>\n",
       "      <td>2.543671e-10</td>\n",
       "      <td>2.869910e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.839579e-13</td>\n",
       "      <td>1.026602e-12</td>\n",
       "      <td>1.370893e-12</td>\n",
       "      <td>1.675137e-12</td>\n",
       "      <td>1.925108e-12</td>\n",
       "      <td>5.839579e-13</td>\n",
       "      <td>1.026602e-12</td>\n",
       "      <td>1.370893e-12</td>\n",
       "      <td>1.675137e-12</td>\n",
       "      <td>1.925108e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>5.839579e-13</td>\n",
       "      <td>1.026602e-12</td>\n",
       "      <td>1.370893e-12</td>\n",
       "      <td>1.675137e-12</td>\n",
       "      <td>1.925108e-12</td>\n",
       "      <td>5.839579e-13</td>\n",
       "      <td>1.026602e-12</td>\n",
       "      <td>1.370893e-12</td>\n",
       "      <td>1.675137e-12</td>\n",
       "      <td>1.925108e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.508418e-09</td>\n",
       "      <td>-2.681711e-09</td>\n",
       "      <td>-3.594315e-09</td>\n",
       "      <td>-4.304158e-09</td>\n",
       "      <td>-4.856293e-09</td>\n",
       "      <td>-1.508418e-09</td>\n",
       "      <td>-2.681711e-09</td>\n",
       "      <td>-3.594315e-09</td>\n",
       "      <td>-4.304158e-09</td>\n",
       "      <td>-4.856293e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.508418e-09</td>\n",
       "      <td>-2.681711e-09</td>\n",
       "      <td>-3.594315e-09</td>\n",
       "      <td>-4.304158e-09</td>\n",
       "      <td>-4.856293e-09</td>\n",
       "      <td>-1.508418e-09</td>\n",
       "      <td>-2.681711e-09</td>\n",
       "      <td>-3.594315e-09</td>\n",
       "      <td>-4.304158e-09</td>\n",
       "      <td>-4.856293e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-3.582425e-09</td>\n",
       "      <td>-6.368896e-09</td>\n",
       "      <td>-8.536285e-09</td>\n",
       "      <td>-1.022213e-08</td>\n",
       "      <td>-1.153341e-08</td>\n",
       "      <td>-3.582425e-09</td>\n",
       "      <td>-6.368896e-09</td>\n",
       "      <td>-8.536285e-09</td>\n",
       "      <td>-1.022213e-08</td>\n",
       "      <td>-1.153341e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.582425e-09</td>\n",
       "      <td>-6.368896e-09</td>\n",
       "      <td>-8.536285e-09</td>\n",
       "      <td>-1.022213e-08</td>\n",
       "      <td>-1.153341e-08</td>\n",
       "      <td>-3.582425e-09</td>\n",
       "      <td>-6.368896e-09</td>\n",
       "      <td>-8.536285e-09</td>\n",
       "      <td>-1.022213e-08</td>\n",
       "      <td>-1.153341e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.750886e-14</td>\n",
       "      <td>3.000256e-14</td>\n",
       "      <td>4.424975e-14</td>\n",
       "      <td>5.704582e-14</td>\n",
       "      <td>6.928223e-14</td>\n",
       "      <td>1.750886e-14</td>\n",
       "      <td>3.000256e-14</td>\n",
       "      <td>4.424975e-14</td>\n",
       "      <td>5.704582e-14</td>\n",
       "      <td>6.928223e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.750886e-14</td>\n",
       "      <td>3.000256e-14</td>\n",
       "      <td>4.424975e-14</td>\n",
       "      <td>5.704582e-14</td>\n",
       "      <td>6.928223e-14</td>\n",
       "      <td>1.750886e-14</td>\n",
       "      <td>3.000256e-14</td>\n",
       "      <td>4.424975e-14</td>\n",
       "      <td>5.704582e-14</td>\n",
       "      <td>6.928223e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.865019e-13</td>\n",
       "      <td>1.400614e-12</td>\n",
       "      <td>1.866956e-12</td>\n",
       "      <td>2.236089e-12</td>\n",
       "      <td>2.516292e-12</td>\n",
       "      <td>7.865019e-13</td>\n",
       "      <td>1.400614e-12</td>\n",
       "      <td>1.866956e-12</td>\n",
       "      <td>2.236089e-12</td>\n",
       "      <td>2.516292e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>7.865019e-13</td>\n",
       "      <td>1.400614e-12</td>\n",
       "      <td>1.866956e-12</td>\n",
       "      <td>2.236089e-12</td>\n",
       "      <td>2.516292e-12</td>\n",
       "      <td>7.865019e-13</td>\n",
       "      <td>1.400614e-12</td>\n",
       "      <td>1.866956e-12</td>\n",
       "      <td>2.236089e-12</td>\n",
       "      <td>2.516292e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          (0, 0)        (0, 1)        (0, 2)        (0, 3)        (0, 4)  \\\n",
       "0   1.156251e+05  2.055607e+05  2.755146e+05  3.299262e+05  3.722487e+05   \n",
       "1  -2.652948e-11 -4.712960e-11 -6.316745e-11 -7.564737e-11 -8.534061e-11   \n",
       "2   8.106073e-12  1.438429e-11  1.926894e-11  2.309931e-11  2.609025e-11   \n",
       "3   1.105025e-11  1.963967e-11  2.632662e-11  3.152202e-11  3.557273e-11   \n",
       "4   4.133934e-12  7.346247e-12  9.846990e-12  1.179033e-11  1.330736e-11   \n",
       "5   2.791923e-11  4.965393e-11  6.652314e-11  7.965457e-11  8.985439e-11   \n",
       "6   3.911601e-13  6.986363e-13  9.333872e-13  1.115161e-12  1.286851e-12   \n",
       "7   1.168265e-12  2.102960e-12  2.845087e-12  3.409722e-12  3.868910e-12   \n",
       "8   9.455376e-12  1.681003e-11  2.259167e-11  2.709936e-11  3.053029e-11   \n",
       "9   8.822633e-12  1.568641e-11  2.103760e-11  2.520139e-11  2.845774e-11   \n",
       "10 -1.233483e-11 -2.192964e-11 -2.939170e-11 -3.519259e-11 -3.970371e-11   \n",
       "11 -1.418991e-12 -2.507512e-12 -3.384340e-12 -4.072562e-12 -4.609681e-12   \n",
       "12  8.915399e-11  1.584820e-10  2.124111e-10  2.543671e-10  2.869910e-10   \n",
       "13  5.839579e-13  1.026602e-12  1.370893e-12  1.675137e-12  1.925108e-12   \n",
       "14 -1.508418e-09 -2.681711e-09 -3.594315e-09 -4.304158e-09 -4.856293e-09   \n",
       "15 -3.582425e-09 -6.368896e-09 -8.536285e-09 -1.022213e-08 -1.153341e-08   \n",
       "16  1.750886e-14  3.000256e-14  4.424975e-14  5.704582e-14  6.928223e-14   \n",
       "17  7.865019e-13  1.400614e-12  1.866956e-12  2.236089e-12  2.516292e-12   \n",
       "\n",
       "          (1, 0)        (1, 1)        (1, 2)        (1, 3)        (1, 4)  \\\n",
       "0   1.156251e+05  2.055607e+05  2.755146e+05  3.299262e+05  3.722487e+05   \n",
       "1  -2.652948e-11 -4.712960e-11 -6.316745e-11 -7.564737e-11 -8.534061e-11   \n",
       "2   8.106073e-12  1.438429e-11  1.926894e-11  2.309931e-11  2.609025e-11   \n",
       "3   1.105025e-11  1.963967e-11  2.632662e-11  3.152202e-11  3.557273e-11   \n",
       "4   4.133934e-12  7.346247e-12  9.846990e-12  1.179033e-11  1.330736e-11   \n",
       "5   2.791923e-11  4.965393e-11  6.652314e-11  7.965457e-11  8.985439e-11   \n",
       "6   3.911601e-13  6.986363e-13  9.333872e-13  1.115161e-12  1.286851e-12   \n",
       "7   1.168265e-12  2.102960e-12  2.845087e-12  3.409722e-12  3.868910e-12   \n",
       "8   9.455376e-12  1.681003e-11  2.259167e-11  2.709936e-11  3.053029e-11   \n",
       "9   8.822633e-12  1.568641e-11  2.103760e-11  2.520139e-11  2.845774e-11   \n",
       "10 -1.233483e-11 -2.192964e-11 -2.939170e-11 -3.519259e-11 -3.970371e-11   \n",
       "11 -1.418991e-12 -2.507512e-12 -3.384340e-12 -4.072562e-12 -4.609681e-12   \n",
       "12  8.915399e-11  1.584820e-10  2.124111e-10  2.543671e-10  2.869910e-10   \n",
       "13  5.839579e-13  1.026602e-12  1.370893e-12  1.675137e-12  1.925108e-12   \n",
       "14 -1.508418e-09 -2.681711e-09 -3.594315e-09 -4.304158e-09 -4.856293e-09   \n",
       "15 -3.582425e-09 -6.368896e-09 -8.536285e-09 -1.022213e-08 -1.153341e-08   \n",
       "16  1.750886e-14  3.000256e-14  4.424975e-14  5.704582e-14  6.928223e-14   \n",
       "17  7.865019e-13  1.400614e-12  1.866956e-12  2.236089e-12  2.516292e-12   \n",
       "\n",
       "        ...             (3, 0)        (3, 1)        (3, 2)        (3, 3)  \\\n",
       "0       ...       1.156251e+05  2.055607e+05  2.755146e+05  3.299262e+05   \n",
       "1       ...      -2.652948e-11 -4.712960e-11 -6.316745e-11 -7.564737e-11   \n",
       "2       ...       8.106073e-12  1.438429e-11  1.926894e-11  2.309931e-11   \n",
       "3       ...       1.105025e-11  1.963967e-11  2.632662e-11  3.152202e-11   \n",
       "4       ...       4.133934e-12  7.346247e-12  9.846990e-12  1.179033e-11   \n",
       "5       ...       2.791923e-11  4.965393e-11  6.652314e-11  7.965457e-11   \n",
       "6       ...       3.911601e-13  6.986363e-13  9.333872e-13  1.115161e-12   \n",
       "7       ...       1.168265e-12  2.102960e-12  2.845087e-12  3.409722e-12   \n",
       "8       ...       9.455376e-12  1.681003e-11  2.259167e-11  2.709936e-11   \n",
       "9       ...       8.822633e-12  1.568641e-11  2.103760e-11  2.520139e-11   \n",
       "10      ...      -1.233483e-11 -2.192964e-11 -2.939170e-11 -3.519259e-11   \n",
       "11      ...      -1.418991e-12 -2.507512e-12 -3.384340e-12 -4.072562e-12   \n",
       "12      ...       8.915399e-11  1.584820e-10  2.124111e-10  2.543671e-10   \n",
       "13      ...       5.839579e-13  1.026602e-12  1.370893e-12  1.675137e-12   \n",
       "14      ...      -1.508418e-09 -2.681711e-09 -3.594315e-09 -4.304158e-09   \n",
       "15      ...      -3.582425e-09 -6.368896e-09 -8.536285e-09 -1.022213e-08   \n",
       "16      ...       1.750886e-14  3.000256e-14  4.424975e-14  5.704582e-14   \n",
       "17      ...       7.865019e-13  1.400614e-12  1.866956e-12  2.236089e-12   \n",
       "\n",
       "          (3, 4)        (4, 0)        (4, 1)        (4, 2)        (4, 3)  \\\n",
       "0   3.722487e+05  1.156251e+05  2.055607e+05  2.755146e+05  3.299262e+05   \n",
       "1  -8.534061e-11 -2.652948e-11 -4.712960e-11 -6.316745e-11 -7.564737e-11   \n",
       "2   2.609025e-11  8.106073e-12  1.438429e-11  1.926894e-11  2.309931e-11   \n",
       "3   3.557273e-11  1.105025e-11  1.963967e-11  2.632662e-11  3.152202e-11   \n",
       "4   1.330736e-11  4.133934e-12  7.346247e-12  9.846990e-12  1.179033e-11   \n",
       "5   8.985439e-11  2.791923e-11  4.965393e-11  6.652314e-11  7.965457e-11   \n",
       "6   1.286851e-12  3.911601e-13  6.986363e-13  9.333872e-13  1.115161e-12   \n",
       "7   3.868910e-12  1.168265e-12  2.102960e-12  2.845087e-12  3.409722e-12   \n",
       "8   3.053029e-11  9.455376e-12  1.681003e-11  2.259167e-11  2.709936e-11   \n",
       "9   2.845774e-11  8.822633e-12  1.568641e-11  2.103760e-11  2.520139e-11   \n",
       "10 -3.970371e-11 -1.233483e-11 -2.192964e-11 -2.939170e-11 -3.519259e-11   \n",
       "11 -4.609681e-12 -1.418991e-12 -2.507512e-12 -3.384340e-12 -4.072562e-12   \n",
       "12  2.869910e-10  8.915399e-11  1.584820e-10  2.124111e-10  2.543671e-10   \n",
       "13  1.925108e-12  5.839579e-13  1.026602e-12  1.370893e-12  1.675137e-12   \n",
       "14 -4.856293e-09 -1.508418e-09 -2.681711e-09 -3.594315e-09 -4.304158e-09   \n",
       "15 -1.153341e-08 -3.582425e-09 -6.368896e-09 -8.536285e-09 -1.022213e-08   \n",
       "16  6.928223e-14  1.750886e-14  3.000256e-14  4.424975e-14  5.704582e-14   \n",
       "17  2.516292e-12  7.865019e-13  1.400614e-12  1.866956e-12  2.236089e-12   \n",
       "\n",
       "          (4, 4)  \n",
       "0   3.722487e+05  \n",
       "1  -8.534061e-11  \n",
       "2   2.609025e-11  \n",
       "3   3.557273e-11  \n",
       "4   1.330736e-11  \n",
       "5   8.985439e-11  \n",
       "6   1.286851e-12  \n",
       "7   3.868910e-12  \n",
       "8   3.053029e-11  \n",
       "9   2.845774e-11  \n",
       "10 -3.970371e-11  \n",
       "11 -4.609681e-12  \n",
       "12  2.869910e-10  \n",
       "13  1.925108e-12  \n",
       "14 -4.856293e-09  \n",
       "15 -1.153341e-08  \n",
       "16  6.928223e-14  \n",
       "17  2.516292e-12  \n",
       "\n",
       "[18 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS of training:  [1.15146667e+14]\n",
      "R^2 of training:  [-8.24526897e-05]\n",
      "MSE of training:  [1.15146667e+11]\n",
      "MSE of test:  [1.67319523e+11]\n"
     ]
    }
   ],
   "source": [
    "class Grad_lin:\n",
    "    # has a coeficients property\n",
    "    # has a fit method\n",
    "\n",
    "    def __init__(self, threshold, alpha, limit=1000):\n",
    "        self._rss = 0\n",
    "        self.n = 0\n",
    "        self._tss = 0\n",
    "        self._alpha = alpha\n",
    "        self.threshold = threshold\n",
    "        self._limit = limit\n",
    "\n",
    "    def get_alpha(self):\n",
    "        return self._alpha\n",
    "\n",
    "    def derivative(self, X, y, j):\n",
    "        # TODO replace with NumPy optimised iterator\n",
    "        d = 0\n",
    "        for i in range(len(X)):\n",
    "            # Good chance this X is wrong here:\n",
    "            # If there are errors on this line, make sure you're getting the ROW i\n",
    "            d += (self._theta.dot(X[i]) - y[i])*X[i, j]\n",
    "        ret = (d*2)/len(X)\n",
    "        return ret\n",
    "\n",
    "    def h(self, x, theta):\n",
    "        x = np.array([x]).T\n",
    "        return theta.T.dot(x)\n",
    "\n",
    "    def cost(self, X, y, theta):\n",
    "        return np.sum(np.power(X.dot(theta) - y, 2))/len(X)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        intercept = np.ones(len(X))\n",
    "        limit = self._limit\n",
    "\n",
    "        X = np.column_stack((intercept, X))\n",
    "        dt = self.threshold + 1\n",
    "        y = np.array([y]).T\n",
    "        self.n = len(X)\n",
    "        n = 0\n",
    "        last_cost = 0\n",
    "        self._theta = np.zeros([X.shape[1], 1])\n",
    "\n",
    "        # This is really hacky\n",
    "        self._old_theta = self._theta + 1\n",
    "        self._cost = np.zeros((limit, 1))\n",
    "\n",
    "        # while not converged\n",
    "        while ((np.linalg.norm(self._theta - self._old_theta) > self.threshold) and (n < limit)):\n",
    "            self._old_theta = self._theta.copy()\n",
    "            for j in range(len(self._theta)):\n",
    "                diff = 0\n",
    "                #here we try to use matrix operations where possible to make use of numpy optimisations\n",
    "                hmatrix = X.dot(self._old_theta)\n",
    "                diff = np.sum(np.multiply((hmatrix - y), X[:, j]))\n",
    "                self._theta[j] = self._old_theta[j]-self._alpha*diff/len(X)\n",
    "            self._cost[n, 0] = self.cost(X, y, self._theta)\n",
    "            last_cost = self._cost[n-1, 0]\n",
    "            #print(self._cost[n, 0], end = \",\")\n",
    "            n += 1\n",
    "        return self\n",
    "\n",
    "    def coef(self):\n",
    "        return self._theta[1:]\n",
    "\n",
    "    def intercept(self):\n",
    "        return self._theta[0]\n",
    "\n",
    "    def rss(self, X, y):\n",
    "        \"\"\"Function assumes no leading ones\"\"\"\n",
    "        rss = 0\n",
    "        for i in range(len(X)):\n",
    "            rss += (y[i] - self.predict(X[i, :]))**2\n",
    "        return rss\n",
    "\n",
    "    def tss(self, X, y):\n",
    "        \"\"\"Function assumes no leading ones\"\"\"\n",
    "        tss = 0\n",
    "        for i in range(len(X)):\n",
    "            tss += (y[i] - y.mean())**2\n",
    "        return tss\n",
    "\n",
    "    def mse(self, X, y):\n",
    "        \"\"\"Function assumes no leading ones\"\"\"\n",
    "        return (self.rss(X, y) / len(X))\n",
    "\n",
    "    def r2(self, X, y):\n",
    "        return 1-(self.rss(X, y)/self.tss(X, y))\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Takes a list of features for a single point, not including a leading 1\"\"\"\n",
    "        return self._theta.T.dot(np.insert(np.array(x), 0, 1))\n",
    "\n",
    "\n",
    "print(\"Running\")\n",
    "\n",
    "X = standardize(housing_training_features)\n",
    "y = housing_training_labels\n",
    "\n",
    "# Create a big table\n",
    "\n",
    "thetatable = pd.DataFrame()\n",
    "alpha = 0.00005\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        lim = (j+1)*25\n",
    "        gradmod = Grad_lin(0.0001, alpha*2, lim)\n",
    "        gradmod.fit(X, y)\n",
    "        thetatable[i, j] = np.insert(gradmod.coef(), 0, gradmod.intercept())\n",
    "        msetable = gradmod.mse(X, y)\n",
    "\n",
    "display(thetatable)\n",
    "#lines = bigtable.plot.line()\n",
    "\n",
    "gradmod = Grad_lin(0.0001, 0.00005, 100)\n",
    "gradmod.fit(X, y)\n",
    "print(\"RSS of training: \", gradmod.rss(X, y))\n",
    "print(\"R^2 of training: \", gradmod.r2(X, y))\n",
    "print(\"MSE of training: \", gradmod.mse(X, y))\n",
    "\n",
    "print(\"MSE of test: \", gradmod.mse(standardize(housing_testing_features), housing_testing_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4 Discussion\n",
    "\n",
    "Since $\\theta$ is a large matrix, it seems that the value of visualisaing the value of $\\theta$ for 25 combinations of $\\alpha$ and the number of iterations will show little. Instead, a line graph can succinctly visualise this data for each of the parameters. This decision was made because a 450 element table seems uninterpretable. \n",
    "\n",
    "\n",
    "##### Comparison with the package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Cost function for alpha= 0.00005')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO Visualise the learning rate\n",
    "\n",
    "plt.plot(gradmod._cost[:,0])\n",
    "plt.title(\"Cost function for alpha= 0.00005\")\n",
    "#TODO Compare this gradient descent to the package\n",
    "\n",
    "clf = linear_model.SGDRegressor(max_iter=1000)\n",
    "clf.fit(X, y)\n",
    "\n",
    "#DO R^2 and MSE to compare\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that around 100 iterations drastically reduces the cost funciton. Running for more than 100 provides a very slight improvement from this point. \n",
    "\n",
    "We see that with learning rates above about "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 [Ridge Regression]\n",
    "\n",
    "PDF Proof can be found on the local file system [here](./Derivation_of_Ridge_Regression.pdf) or though [GitHub](https://github.com/cdilga/DS4400/blob/master/DS4400_HW1/Derivation_of_Ridge_Regression.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\text{Predicted}=689731.07 \\space ft^2\\\\ \\text{Actual}= 700000.0\\space ft^2$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$RSS = 31862677597299.113 \\\\ MSE = 31862677597.299114 \\\\ R^2 = 0.7233$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RSS</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>6.372536e+10</td>\n",
       "      <td>6.372536e+13</td>\n",
       "      <td>0.723263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>9.560907e+10</td>\n",
       "      <td>9.560907e+13</td>\n",
       "      <td>0.723202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.275492e+11</td>\n",
       "      <td>1.275492e+14</td>\n",
       "      <td>0.723049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>1.595678e+11</td>\n",
       "      <td>1.595678e+14</td>\n",
       "      <td>0.722821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1.916792e+11</td>\n",
       "      <td>1.916792e+14</td>\n",
       "      <td>0.722535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5</th>\n",
       "      <td>2.238929e+11</td>\n",
       "      <td>2.238929e+14</td>\n",
       "      <td>0.722204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2.562145e+11</td>\n",
       "      <td>2.562145e+14</td>\n",
       "      <td>0.721838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.5</th>\n",
       "      <td>2.886472e+11</td>\n",
       "      <td>2.886472e+14</td>\n",
       "      <td>0.721446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>3.211923e+11</td>\n",
       "      <td>3.211923e+14</td>\n",
       "      <td>0.721035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.5</th>\n",
       "      <td>3.538501e+11</td>\n",
       "      <td>3.538501e+14</td>\n",
       "      <td>0.720610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>3.866197e+11</td>\n",
       "      <td>3.866197e+14</td>\n",
       "      <td>0.720175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.5</th>\n",
       "      <td>4.194998e+11</td>\n",
       "      <td>4.194998e+14</td>\n",
       "      <td>0.719732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>4.524887e+11</td>\n",
       "      <td>4.524887e+14</td>\n",
       "      <td>0.719286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.5</th>\n",
       "      <td>4.855841e+11</td>\n",
       "      <td>4.855841e+14</td>\n",
       "      <td>0.718837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>5.187838e+11</td>\n",
       "      <td>5.187838e+14</td>\n",
       "      <td>0.718388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.5</th>\n",
       "      <td>5.520855e+11</td>\n",
       "      <td>5.520855e+14</td>\n",
       "      <td>0.717940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>5.854865e+11</td>\n",
       "      <td>5.854865e+14</td>\n",
       "      <td>0.717493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.5</th>\n",
       "      <td>6.189844e+11</td>\n",
       "      <td>6.189844e+14</td>\n",
       "      <td>0.717049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>6.525767e+11</td>\n",
       "      <td>6.525767e+14</td>\n",
       "      <td>0.716609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.5</th>\n",
       "      <td>6.862610e+11</td>\n",
       "      <td>6.862610e+14</td>\n",
       "      <td>0.716173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              MSE           RSS       R^2\n",
       "0.0  6.372536e+10  6.372536e+13  0.723263\n",
       "0.5  9.560907e+10  9.560907e+13  0.723202\n",
       "1.0  1.275492e+11  1.275492e+14  0.723049\n",
       "1.5  1.595678e+11  1.595678e+14  0.722821\n",
       "2.0  1.916792e+11  1.916792e+14  0.722535\n",
       "2.5  2.238929e+11  2.238929e+14  0.722204\n",
       "3.0  2.562145e+11  2.562145e+14  0.721838\n",
       "3.5  2.886472e+11  2.886472e+14  0.721446\n",
       "4.0  3.211923e+11  3.211923e+14  0.721035\n",
       "4.5  3.538501e+11  3.538501e+14  0.720610\n",
       "5.0  3.866197e+11  3.866197e+14  0.720175\n",
       "5.5  4.194998e+11  4.194998e+14  0.719732\n",
       "6.0  4.524887e+11  4.524887e+14  0.719286\n",
       "6.5  4.855841e+11  4.855841e+14  0.718837\n",
       "7.0  5.187838e+11  5.187838e+14  0.718388\n",
       "7.5  5.520855e+11  5.520855e+14  0.717940\n",
       "8.0  5.854865e+11  5.854865e+14  0.717493\n",
       "8.5  6.189844e+11  6.189844e+14  0.717049\n",
       "9.0  6.525767e+11  6.525767e+14  0.716609\n",
       "9.5  6.862610e+11  6.862610e+14  0.716173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'MSE by Lambda for Ridge Regression')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Ridge_reg:\n",
    "    # has a coeficients property\n",
    "    # has a fit method\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.theta = np.ones((1,))\n",
    "        self._rss = 0\n",
    "        self.n = 0\n",
    "        self._tss = 0\n",
    "        \n",
    "    def fit(self, X, y, lda): \n",
    "        #We need to add a column of ones to x to allow the intercept to work\n",
    "        \n",
    "        self.n = X.shape[0]\n",
    "        intercept = np.ones(len(X))\n",
    " \n",
    "        X = np.column_stack((intercept, X))\n",
    "        \n",
    "        y_m = y.mean()\n",
    "        #use theta\n",
    "        self.theta = np.linalg.pinv(X.T.dot(X) + lda * np.identity(X.shape[1])).dot(X.T).dot(y)\n",
    "\n",
    "        self._calc_rss(X, y, y_m)\n",
    "        return self\n",
    "    \n",
    "    def coef(self):\n",
    "        return self.theta[1:]\n",
    "    \n",
    "    def intercept(self):\n",
    "        return self.theta[0]\n",
    "    \n",
    "    def _calc_rss(self, X, y, y_m):\n",
    "        #we have to strip off all of the leading 1's\n",
    "        for i in range(self.n):\n",
    "            self._rss += (y[i] - self.predict(X[i,1:]))**2\n",
    "            self._tss += (y[i] - y_m)**2\n",
    "            \n",
    "    def mse(self):\n",
    "        return (self._rss / self.n)\n",
    "        \n",
    "    def rss(self):\n",
    "        return self._rss\n",
    "    \n",
    "    def r2(self):\n",
    "        return 1-(self._rss/self._tss)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.theta.T.dot(np.insert(x, 0, 1))\n",
    "    \n",
    "    \n",
    "ridge = Ridge_reg()\n",
    "\n",
    "# Prediction of price using new multidimensional data point\n",
    "\n",
    "ridge.fit(np.array(housing_training_features), housing_training_labels, 0)\n",
    "model = ridge.predict(np.array(housing_testing_features.loc[0,:]))\n",
    "actual = housing_testing_labels[0]\n",
    "\n",
    "display(Math(\"\\\\text{Predicted}=\" + \n",
    "             str(round(model, 2)) + \n",
    "             \" \\\\space ft^2\\\\\\\\ \\\\text{Actual}= \" + \n",
    "             str(round(actual, 2)) + \n",
    "             \"\\\\space ft^2\"\n",
    "            ))\n",
    "\n",
    "display(Math(\"RSS = {0} \\\\\\\\ MSE = {1} \\\\\\\\ R^2 = {2:.4f}\".format(ridge.rss(), ridge.mse(), ridge.r2())))\n",
    "\n",
    "result = pd.DataFrame()\n",
    "for i in range(0, 100, 5):\n",
    "    lda = i/10\n",
    "    ridge.fit(np.array(housing_training_features), housing_training_labels, lda)\n",
    "    result.loc[str(lda), \"MSE\"] = ridge.mse()\n",
    "    result.loc[str(lda), \"RSS\"] = ridge.rss()\n",
    "    result.loc[str(lda), \"R^2\"] = ridge.r2()\n",
    "    \n",
    "    \n",
    "display(result)\n",
    "\n",
    "plt.plot(result.loc[:,\"MSE\"])\n",
    "plt.title(\"MSE by Lambda for Ridge Regression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very clear that the effect of $\\lambda$ is steadily negative"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
