{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS44000 Homework 1\n",
    "\n",
    "Chris Dilger\n",
    "\n",
    "Code available on GitHub: https://github.com/cdilga/DS4400/blob/master/Homework%201.ipynb\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "## Problem 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>520414.834000</td>\n",
       "      <td>339488.477270</td>\n",
       "      <td>80000.0000</td>\n",
       "      <td>3.075000e+06</td>\n",
       "      <td>1.152524e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>3.349000</td>\n",
       "      <td>0.852012</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>7.259249e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>2.045750</td>\n",
       "      <td>0.721623</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.207402e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living</th>\n",
       "      <td>2051.196000</td>\n",
       "      <td>887.929222</td>\n",
       "      <td>380.0000</td>\n",
       "      <td>6.070000e+03</td>\n",
       "      <td>7.884183e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot</th>\n",
       "      <td>14702.085000</td>\n",
       "      <td>28961.030775</td>\n",
       "      <td>649.0000</td>\n",
       "      <td>3.153740e+05</td>\n",
       "      <td>8.387413e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floors</th>\n",
       "      <td>1.446500</td>\n",
       "      <td>0.517354</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>2.676554e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterfront</th>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.089129</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.943944e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>view</th>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.765125</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>5.854164e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <td>3.464000</td>\n",
       "      <td>0.689332</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>4.751792e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>7.606000</td>\n",
       "      <td>1.160220</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>1.346110e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_above</th>\n",
       "      <td>1750.333000</td>\n",
       "      <td>790.077476</td>\n",
       "      <td>380.0000</td>\n",
       "      <td>6.070000e+03</td>\n",
       "      <td>6.242224e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_basement</th>\n",
       "      <td>300.863000</td>\n",
       "      <td>450.898196</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.060000e+03</td>\n",
       "      <td>2.033092e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr_built</th>\n",
       "      <td>1969.049000</td>\n",
       "      <td>28.190873</td>\n",
       "      <td>1900.0000</td>\n",
       "      <td>2.015000e+03</td>\n",
       "      <td>7.947253e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr_renovated</th>\n",
       "      <td>81.749000</td>\n",
       "      <td>395.578250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.014000e+03</td>\n",
       "      <td>1.564822e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>47.549493</td>\n",
       "      <td>0.141670</td>\n",
       "      <td>47.1775</td>\n",
       "      <td>4.777760e+01</td>\n",
       "      <td>2.007034e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>-122.207472</td>\n",
       "      <td>0.139509</td>\n",
       "      <td>-122.4900</td>\n",
       "      <td>-1.217090e+02</td>\n",
       "      <td>1.946285e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living15</th>\n",
       "      <td>1987.077000</td>\n",
       "      <td>670.439353</td>\n",
       "      <td>830.0000</td>\n",
       "      <td>4.760000e+03</td>\n",
       "      <td>4.494889e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot15</th>\n",
       "      <td>13496.874000</td>\n",
       "      <td>25093.829486</td>\n",
       "      <td>660.0000</td>\n",
       "      <td>2.339710e+05</td>\n",
       "      <td>6.297003e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean            std         min           max  \\\n",
       "price          520414.834000  339488.477270  80000.0000  3.075000e+06   \n",
       "bedrooms            3.349000       0.852012      0.0000  7.000000e+00   \n",
       "bathrooms           2.045750       0.721623      0.0000  5.000000e+00   \n",
       "sqft_living      2051.196000     887.929222    380.0000  6.070000e+03   \n",
       "sqft_lot        14702.085000   28961.030775    649.0000  3.153740e+05   \n",
       "floors              1.446500       0.517354      1.0000  3.500000e+00   \n",
       "waterfront          0.008000       0.089129      0.0000  1.000000e+00   \n",
       "view                0.237000       0.765125      0.0000  4.000000e+00   \n",
       "condition           3.464000       0.689332      1.0000  5.000000e+00   \n",
       "grade               7.606000       1.160220      4.0000  1.200000e+01   \n",
       "sqft_above       1750.333000     790.077476    380.0000  6.070000e+03   \n",
       "sqft_basement     300.863000     450.898196      0.0000  2.060000e+03   \n",
       "yr_built         1969.049000      28.190873   1900.0000  2.015000e+03   \n",
       "yr_renovated       81.749000     395.578250      0.0000  2.014000e+03   \n",
       "lat                47.549493       0.141670     47.1775  4.777760e+01   \n",
       "long             -122.207472       0.139509   -122.4900 -1.217090e+02   \n",
       "sqft_living15    1987.077000     670.439353    830.0000  4.760000e+03   \n",
       "sqft_lot15      13496.874000   25093.829486    660.0000  2.339710e+05   \n",
       "\n",
       "                        var  \n",
       "price          1.152524e+11  \n",
       "bedrooms       7.259249e-01  \n",
       "bathrooms      5.207402e-01  \n",
       "sqft_living    7.884183e+05  \n",
       "sqft_lot       8.387413e+08  \n",
       "floors         2.676554e-01  \n",
       "waterfront     7.943944e-03  \n",
       "view           5.854164e-01  \n",
       "condition      4.751792e-01  \n",
       "grade          1.346110e+00  \n",
       "sqft_above     6.242224e+05  \n",
       "sqft_basement  2.033092e+05  \n",
       "yr_built       7.947253e+02  \n",
       "yr_renovated   1.564822e+05  \n",
       "lat            2.007034e-02  \n",
       "long           1.946285e-02  \n",
       "sqft_living15  4.494889e+05  \n",
       "sqft_lot15     6.297003e+08  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cols(data, width = 30):\n",
    "    \"\"\"Formats list like objects into columns\"\"\"\n",
    "    return \"\".join(str(word).ljust(30) for word in data)\n",
    "\n",
    "                   \n",
    "# Load the file\n",
    "housing = pd.read_csv(\"data/train.csv\", \n",
    "                      usecols=lambda x: x in [\"price\",\n",
    "                                              \"bedrooms\",\n",
    "                                              \"bathrooms\",\n",
    "                                              \"sqft_living\",\n",
    "                                              \"sqft_lot\",\n",
    "                                              \"floors\",\n",
    "                                              \"waterfront\",\n",
    "                                              \"view\",\n",
    "                                              \"condition\",\n",
    "                                              \"grade\",\n",
    "                                              \"sqft_above\",\n",
    "                                              \"sqft_basement\",\n",
    "                                              \"yr_built\",\n",
    "                                              \"yr_renovated\",\n",
    "                                              \"lat\",\n",
    "                                              \"long\",\n",
    "                                              \"sqft_living15\",\n",
    "                                              \"sqft_lot15\"])\n",
    "\n",
    "housing_test = pd.read_csv(\"data/test.csv\", \n",
    "                      usecols=lambda x: x in [\"price\",\n",
    "                                              \"bedrooms\",\n",
    "                                              \"bathrooms\",\n",
    "                                              \"sqft_living\",\n",
    "                                              \"sqft_lot\",\n",
    "                                              \"floors\",\n",
    "                                              \"waterfront\",\n",
    "                                              \"view\",\n",
    "                                              \"condition\",\n",
    "                                              \"grade\",\n",
    "                                              \"sqft_above\",\n",
    "                                              \"sqft_basement\",\n",
    "                                              \"yr_built\",\n",
    "                                              \"yr_renovated\",\n",
    "                                              \"lat\",\n",
    "                                              \"long\",\n",
    "                                              \"sqft_living15\",\n",
    "                                              \"sqft_lot15\"])\n",
    "\n",
    "\n",
    "housing_training_features = housing.copy().drop(\"price\", axis=1)\n",
    "housing_training_labels = housing.copy().loc[:,\"price\"]\n",
    "housing_testing_features = housing_test.copy().drop(\"price\", axis=1)\n",
    "housing_testing_labels = housing_test.copy().loc[:,\"price\"]\n",
    "\n",
    "description = housing.describe().loc[[\"mean\", \"std\", \"min\", \"max\"]]\n",
    "description = description.T\n",
    "description['var'] = description['std'].apply(lambda x: x**2)\n",
    "description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedrooms                      0.3070584002104321            0.3070584002104319            \n",
      "bathrooms                     0.48715729789866974           0.4871572978986769            \n",
      "sqft_living                   0.7047757101823997            0.7047757101824055            \n",
      "sqft_lot                      0.14664482983805222           0.14664482983805197           \n",
      "floors                        0.2399348472639126            0.2399348472639161            \n",
      "waterfront                    0.31714301382621846           0.3171430138262226            \n",
      "view                          0.44531642588846515           0.4453164258884609            \n",
      "condition                     0.07396055390188862           0.07396055390188938           \n",
      "grade                         0.647349055785599             0.6473490557856066            \n",
      "sqft_above                    0.5824071469756538            0.5824071469756582            \n",
      "sqft_basement                 0.3673649191324655            0.36736491913246594           \n",
      "yr_built                      0.01605485919669362           0.016054859196693777          \n",
      "yr_renovated                  0.1463481824398023            0.14634818243980063           \n",
      "lat                           0.36576970790785424           0.36576970790785757           \n",
      "long                          0.0328455635948112            0.03284556359481139           \n",
      "sqft_living15                 0.6451060081578837            0.6451060081578872            \n",
      "sqft_lot15                    0.16174626078384294           0.16174626078384322           \n"
     ]
    }
   ],
   "source": [
    "def cov(x, y):\n",
    "    \"\"\"Calculate covariance given the feature x and response y\"\"\"\n",
    "    total = 0\n",
    "    x_m = x.mean()\n",
    "    y_m = y.mean()\n",
    "    for i in range(len(x)):\n",
    "        total += (x.loc[i]-x_m)*(y.loc[i]-y_m)\n",
    "    return total/(len(x)-1)\n",
    "\n",
    "def cor(x, y):\n",
    "    \"\"\"Calculate the correlation coefficient\"\"\"\n",
    "    return cov(x, y)/(x.std()*y.std())\n",
    "\n",
    "for feature in [x for x in housing if x != \"price\"]:\n",
    "    print(cols([feature, \n",
    "                cor(housing[\"price\"], housing[feature]),\n",
    "                housing[\"price\"].corr(housing[feature])\n",
    "               ]))\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion of Problem 1.a\n",
    "Suprisingly every feature is positively correlated with price, which is suprising. `yr_built` and `yr_renovated` are weakly correlated, as were `long` (longditude) and `sqft_lot15`. \n",
    "\n",
    "\n",
    "## Problem 2 [Linear regression]\n",
    "\n",
    "### (a) \n",
    "Use an existing package to train a linear regression model on the training set. Report the coefficients of the linear regression models and the 3 metrics of interest: MSE, RSS, and $R^2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$R^2 = 0.7265$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$MSE=31486167776$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$RSS=31486167775795$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use scikit.learn\n",
    "\n",
    "#Get MSE RSS and R^2\n",
    "\n",
    "#All predictors predicting 'price' label\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from IPython.display import display, Math\n",
    "from sklearn import metrics\n",
    "\n",
    "def lib_metrics(r, features, labels):\n",
    "    display(Math(\"R^2 = {0:.4f}\".format(r.score(features, labels))))\n",
    "    mse = metrics.mean_squared_error(labels, r.predict(features))\n",
    "    display(Math(\"MSE={0:.0f}\".format(mse)))\n",
    "\n",
    "    rss = mse*len(labels)\n",
    "    display(Math(\"RSS={0:.0f}\".format(rss)))\n",
    "\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(housing_training_features, housing_training_labels)\n",
    "\n",
    "lib_metrics(reg, housing_training_features, housing_training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) \n",
    "Perform feature standardization so that each feature has mean 0 and variance of 1. Train again a linear regression model on the training data. Compare the results with the previous models in terms of the metrics of interest: MSE, RSS, and $R^2$.\n",
    "\n",
    "### (c)\n",
    "Evaluate both models on the testing set. Report the same metrics (MSE, RSE, and $R^2$) on the testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$R^2 = 0.7265$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$MSE=31486167776$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$RSS=31486167775795$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Scaling R^2:  0.7265334318706016\n",
      "With Scaling R^2:  0.7265334318706018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standardized</th>\n",
       "      <th>Unstandardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>-1035.203084</td>\n",
       "      <td>-7424.027121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floors</th>\n",
       "      <td>8043.720837</td>\n",
       "      <td>15555.580988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot</th>\n",
       "      <td>10881.868446</td>\n",
       "      <td>0.375930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>-12521.961869</td>\n",
       "      <td>-14704.280497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot15</th>\n",
       "      <td>-12930.090978</td>\n",
       "      <td>-0.515528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <td>12964.269364</td>\n",
       "      <td>18816.402756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr_renovated</th>\n",
       "      <td>17271.379530</td>\n",
       "      <td>43.682942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>18527.632513</td>\n",
       "      <td>25687.783987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_basement</th>\n",
       "      <td>27137.032468</td>\n",
       "      <td>41.073715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living15</th>\n",
       "      <td>45577.657813</td>\n",
       "      <td>68.015792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>view</th>\n",
       "      <td>48200.108524</td>\n",
       "      <td>63027.898001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_above</th>\n",
       "      <td>48290.088862</td>\n",
       "      <td>42.010495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living</th>\n",
       "      <td>56748.836801</td>\n",
       "      <td>83.084210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterfront</th>\n",
       "      <td>63742.899560</td>\n",
       "      <td>715535.170469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr_built</th>\n",
       "      <td>-67643.117413</td>\n",
       "      <td>-2400.669330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>78375.736932</td>\n",
       "      <td>553505.032276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>92231.474822</td>\n",
       "      <td>79534.602722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Standardized  Unstandardized\n",
       "long           -1035.203084    -7424.027121\n",
       "floors          8043.720837    15555.580988\n",
       "sqft_lot       10881.868446        0.375930\n",
       "bedrooms      -12521.961869   -14704.280497\n",
       "sqft_lot15    -12930.090978       -0.515528\n",
       "condition      12964.269364    18816.402756\n",
       "yr_renovated   17271.379530       43.682942\n",
       "bathrooms      18527.632513    25687.783987\n",
       "sqft_basement  27137.032468       41.073715\n",
       "sqft_living15  45577.657813       68.015792\n",
       "view           48200.108524    63027.898001\n",
       "sqft_above     48290.088862       42.010495\n",
       "sqft_living    56748.836801       83.084210\n",
       "waterfront     63742.899560   715535.170469\n",
       "yr_built      -67643.117413    -2400.669330\n",
       "lat            78375.736932   553505.032276\n",
       "grade          92231.474822    79534.602722"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We should be able to pass this a dataset, then it normalises it. Will also expose functions to normalise further bits\n",
    "# It seems that \"unstandardisation\" isn't really a thing\n",
    "def standardize(features):\n",
    "    #iterate through the features\n",
    "    features = np.array(features)\n",
    "    \n",
    "    #Nice function which copies the shape of features into a new array\n",
    "    scaled = np.empty_like(features)\n",
    "    for i in range(len(features.T)):\n",
    "        mu = features[:,i].mean()\n",
    "        sd = features[:,i].std()\n",
    "\n",
    "        for j in range(len(features[:,i])):\n",
    "            scaled[j,i] = (features[j,i] - mu)/sd\n",
    "            \n",
    "    return scaled\n",
    "\n",
    "stdreg = linear_model.LinearRegression(normalize=False)\n",
    "stdfeatures = standardize(housing_training_features)\n",
    "stdreg.fit(stdfeatures, housing_training_labels)\n",
    "\n",
    "lib_metrics(stdreg, stdfeatures, housing_training_labels)\n",
    "\n",
    "print(\"Without Scaling R^2: \", reg.score(housing_training_features, housing_training_labels))\n",
    "print(\"With Scaling R^2: \", stdreg.score(stdfeatures, housing_training_labels))\n",
    "labs = [label for label in housing_training_features]\n",
    "\n",
    "stdcomp = pd.DataFrame({\"Standardized\" : pd.Series(stdreg.coef_, index=labs), \n",
    "              \"Unstandardized\" : pd.Series(reg.coef_, index=labs)})\n",
    "stdcomp.reindex(stdcomp.loc[:,\"Standardized\"].abs().sort_values(inplace=False).index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly the $R^2$ value, MSE and RSS have remained the same whether or not the data has been normalised. We would expect a difference in convergence time however, when we construct the gradient descent model in Problem 4\n",
    "\n",
    "### (d) \n",
    "Interpret the results in your own words. Which features contribute mostly to the linear regression model? Is the model fitting the data well? How large is the model error?\n",
    "\n",
    "We see that the features with the largest theta values contribute the most to the linear regression. Results were ordered by their absolute value to include negative effects. Several results are unexpected, especially the negative correlation between bedrooms and price. A basic graph below demonstrates this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e392a6c438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot housing.loc[:,\"bedrooms\"],housing.loc[:,\"price\"]\n",
    "import matplotlib.pyplot as plt\n",
    "display(plt.scatter(housing.loc[:,\"bedrooms\"], housing.loc[:,\"price\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a positive correlation before we account for all other features\n",
    "\n",
    "The model is fitting the data reasonably well, $R^2$ shows that 72.65% of the variation in the data can be explained by the multiple linear model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 [Closed form solution of linear regression]\n",
    "\n",
    "\n",
    "In this problem, you will implement your own linear regression model, using the closed-form solution we derived in class. You will also compare your model with the one trained with the package.\n",
    "\n",
    "\n",
    "1. Implement simple linear regression and train a model for one feature (sqft\\_living) using the training set. Write code to predict a response for a new single-dimensional data point in the testing set.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\theta_0 = -32304.6547, \\theta_1 = 269.4621$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$\\text{Predicted}=388056.15 \\space ft^2\\\\ \\text{Actual}= 270000.0\\space ft^2$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$RSS = 57947526161288.3594 \\\\ MSE = 57947526161.2884 \\\\ R^2 = 0.4967$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Lin:\n",
    "    \"\"\"Fit a linear model to some datapoints in 2 dimensions\"\"\"\n",
    "    def __init__(self):\n",
    "        self.theta = np.ones(2)\n",
    "        self._rss = 0\n",
    "        self.n = 0\n",
    "        self._tss = 0\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        \"\"\"Takes X Feature numpy 1d array, y Label numpy 1d array\"\"\"\n",
    "        \n",
    "        self.n = X.shape[0]\n",
    "        \n",
    "        x_m = np.mean(X)\n",
    "        y_m = np.mean(y)\n",
    "        \n",
    "        # for each training data point in x, and corresponding label y\n",
    "        # calculate 2 separate values, using this formula and a mean of each\n",
    "        a = b = 0\n",
    "        for i in range(self.n):\n",
    "            diffx = X[i]-x_m\n",
    "            a += (diffx)*(y[i]-y_m)\n",
    "            b += (diffx)**2\n",
    "            \n",
    "        self.theta[1] = a/b\n",
    "        self.theta[0] = y_m-self.theta[1]*x_m\n",
    "        \n",
    "        for i in range(self.n):\n",
    "            self._rss += (y[i] - self.predict(X[i]))**2\n",
    "            self._tss += (y[i] - y_m)**2\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def rss(self):\n",
    "        return self._rss\n",
    "    \n",
    "    def mse(self):\n",
    "        return (self._rss / self.n)\n",
    "    \n",
    "    def r2(self):\n",
    "        return 1-(self._rss/self._tss)\n",
    "    \n",
    "    def coef(self):\n",
    "        \"\"\"Return the coefficients vector\"\"\"\n",
    "        return self.theta\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.theta[0] + x*self.theta[1]\n",
    "\n",
    "mod = Lin()\n",
    "\n",
    "housing_training_features\n",
    "mod.fit(housing.loc[:,'sqft_living'], housing.loc[:,'price'])\n",
    "\n",
    "thetas = mod.coef()\n",
    "display(Math(\"\\\\theta_0 = {0:.4f}, \\\\theta_1 = {1:.4f}\".format(thetas[0], thetas[1])))\n",
    "\n",
    "predict = housing_test.loc[1,'sqft_living']\n",
    "model = mod.predict(predict)\n",
    "actual = housing_test.loc[1,'price']\n",
    "\n",
    "display(Math(\"\\\\text{Predicted}=\" + \n",
    "             str(round(model, 2)) + \n",
    "             \" \\\\space ft^2\\\\\\\\ \\\\text{Actual}= \" + \n",
    "             str(round(actual, 2)) + \n",
    "             \"\\\\space ft^2\"\n",
    "            ))\n",
    "\n",
    "display(Math(\"RSS = {:.4f} \\\\\\\\ MSE = {:.4f} \\\\\\\\ R^2 = {:.4f}\".format(mod.rss(), mod.mse(), mod.r2())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement multiple linear regression using matrix operations and train a model on the training set. Write code to predict a response for a new multi-dimensional data point in the testing set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\text{Predicted}=689731.07 \\space ft^2\\\\ \\text{Actual}= 700000.0\\space ft^2$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$RSS = 31862677597299.113 \\\\ MSE = 31862677597.299114 \\\\ R^2 = 0.7233$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Multi_lin:\n",
    "    # has a coeficients property\n",
    "    # has a fit method\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.theta = np.ones((1,))\n",
    "        self._rss = 0\n",
    "        self.n = 0\n",
    "        self._tss = 0\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        #We need to add a column of ones to x to allow the intercept to work\n",
    "        \n",
    "        self.n = X.shape[0]\n",
    "        intercept = np.ones(len(X))\n",
    " \n",
    "        X = np.column_stack((intercept, X))\n",
    "        \n",
    "        y_m = y.mean()\n",
    "        #use theta\n",
    "        self.theta = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "        self._calc_rss(X, y, y_m)\n",
    "        return self\n",
    "    \n",
    "    def coef(self):\n",
    "        return self.theta[1:]\n",
    "    \n",
    "    def intercept(self):\n",
    "        return self.theta[0]\n",
    "    \n",
    "    def _calc_rss(self, X, y, y_m):\n",
    "        #we have to strip off all of the leading 1's\n",
    "        for i in range(self.n):\n",
    "            self._rss += (y[i] - self.predict(X[i,1:]))**2\n",
    "            self._tss += (y[i] - y_m)**2\n",
    "            \n",
    "    def mse(self):\n",
    "        return (self._rss / self.n)\n",
    "        \n",
    "    def rss(self):\n",
    "        return self._rss\n",
    "    \n",
    "    def r2(self):\n",
    "        return 1-(self._rss/self._tss)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.theta.T.dot(np.insert(x, 0, 1))\n",
    "    \n",
    "    \n",
    "mult = Multi_lin()\n",
    "\n",
    "# Prediction of price using new multidimensional data point\n",
    "\n",
    "mult.fit(np.array(housing_training_features), housing_training_labels)\n",
    "model = mult.predict(np.array(housing_testing_features.loc[0,:]))\n",
    "actual = housing_testing_labels[0]\n",
    "\n",
    "display(Math(\"\\\\text{Predicted}=\" + \n",
    "             str(round(model, 2)) + \n",
    "             \" \\\\space ft^2\\\\\\\\ \\\\text{Actual}= \" + \n",
    "             str(round(actual, 2)) + \n",
    "             \"\\\\space ft^2\"\n",
    "            ))\n",
    "\n",
    "display(Math(\"RSS = {0} \\\\\\\\ MSE = {1} \\\\\\\\ R^2 = {2:.4f}\".format(mult.rss(), mult.mse() , mult.r2())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compare the models given by your implementation with those trained in Problem 2 by the R or Python packages. Report the MSE, RSE, and $R^2$ metrics for the models you implemented. Compare the coefficients output by your model with the ones computed by the package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple linear regression\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$RSS = 57947526161288.3594 \\\\ MSE = 57947526161.2884 \\\\ R^2 = 0.4967$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple linear regression library:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$R^2 = 0.4967$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$MSE=57947526161$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$RSS=57947526161288$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple linear regression: \n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$RSS = 31862677597299.1133 \\\\ MSE = 31862677597.2991 \\\\ R^2 = 0.7233$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple linear regression library\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$R^2 = 0.7265$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$MSE=31486167776$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$RSS=31486167775795$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>multiple_code</th>\n",
       "      <th>multiple_library</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-470.805669</td>\n",
       "      <td>-2.308890e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-15737.805001</td>\n",
       "      <td>-1.470428e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26264.450129</td>\n",
       "      <td>2.568778e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.504985</td>\n",
       "      <td>8.308421e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.350240</td>\n",
       "      <td>3.759298e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23344.816106</td>\n",
       "      <td>1.555558e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>725344.412572</td>\n",
       "      <td>7.155352e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65223.592066</td>\n",
       "      <td>6.302790e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16620.915477</td>\n",
       "      <td>1.881640e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>85550.566113</td>\n",
       "      <td>7.953460e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.327279</td>\n",
       "      <td>4.201050e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48.177874</td>\n",
       "      <td>4.107372e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2896.687815</td>\n",
       "      <td>-2.400669e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>39.137433</td>\n",
       "      <td>4.368294e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>508933.461024</td>\n",
       "      <td>5.535050e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>156340.326253</td>\n",
       "      <td>-7.424027e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>58.171586</td>\n",
       "      <td>6.801579e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.639549</td>\n",
       "      <td>-5.155276e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    multiple_code  multiple_library\n",
       "0     -470.805669     -2.308890e+07\n",
       "1   -15737.805001     -1.470428e+04\n",
       "2    26264.450129      2.568778e+04\n",
       "3       84.504985      8.308421e+01\n",
       "4        0.350240      3.759298e-01\n",
       "5    23344.816106      1.555558e+04\n",
       "6   725344.412572      7.155352e+05\n",
       "7    65223.592066      6.302790e+04\n",
       "8    16620.915477      1.881640e+04\n",
       "9    85550.566113      7.953460e+04\n",
       "10      36.327279      4.201050e+01\n",
       "11      48.177874      4.107372e+01\n",
       "12   -2896.687815     -2.400669e+03\n",
       "13      39.137433      4.368294e+01\n",
       "14  508933.461024      5.535050e+05\n",
       "15  156340.326253     -7.424027e+03\n",
       "16      58.171586      6.801579e+01\n",
       "17      -0.639549     -5.155276e-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Linear model trained:\n",
    "print(\"Simple linear regression\")\n",
    "display(Math(\"RSS = {:.4f} \\\\\\\\ MSE = {:.4f} \\\\\\\\ R^2 = {:.4f}\".format(mod.rss(), mod.mse(), mod.r2())))\n",
    "\n",
    "#libaray simple linear regression\n",
    "simplereg = linear_model.LinearRegression()\n",
    "features = np.array(housing_training_features.loc[:,\"sqft_living\"])[:, np.newaxis]\n",
    "labels = np.array(housing_training_labels)[:, np.newaxis]\n",
    "simplereg.fit(features, housing_training_labels)\n",
    "\n",
    "\n",
    "print(\"Simple linear regression library:\")\n",
    "display(Math(\"R^2 = {0:.4f}\".format(simplereg.score(features, housing_training_labels))))\n",
    "simpleregmse = metrics.mean_squared_error(labels, simplereg.predict(features))\n",
    "display(Math(\"MSE={0:.0f}\".format(simpleregmse)))\n",
    "\n",
    "simpleregrss = simpleregmse*len(housing_training_labels)\n",
    "display(Math(\"RSS={0:.0f}\".format(simpleregrss)))\n",
    "\n",
    "#Multiple linear model trained:\n",
    "print(\"Multiple linear regression: \")\n",
    "display(Math(\"RSS = {0:.4f} \\\\\\\\ MSE = {1:.4f} \\\\\\\\ R^2 = {2:.4f}\".format(mult.rss(), mult.mse(), mult.r2())))\n",
    "\n",
    "print(\"Multiple linear regression library\")\n",
    "lib_metrics(reg, housing_training_features, housing_training_labels)\n",
    "\n",
    "output = pd.DataFrame()\n",
    "# This mult.coef is 17 long. This is equal to the number of predictors\n",
    "#however we also need an intercept --- Where is the intercept?\n",
    "output[\"multiple_code\"] = np.insert(mult.coef(), 0, mult.intercept())\n",
    "\n",
    "output[\"multiple_library\"] = np.insert(reg.coef_, 0, reg.intercept_)\n",
    "\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 [Gradient Descent]\n",
    "\n",
    "In this problem, you will implement your own gradient descent algorithm and apply it to linear regression. Use the scaled dataset.\n",
    "\n",
    "(a) Write code for gradient descent for training linear regression using the algorithm from class.\n",
    "\n",
    "(b) Vary the value of the learning rate (5 different values) and the number of iterations (5 different values)) and report the value of $\\theta$ for each of the 25 combinations, as well as the MSE metric on the training set. Report the MSE on the testing set.\n",
    "\n",
    "(c) Tune your implementation to obtain results close to those obtained with the package. Write some observations: How does the objective change with different learning rates; how many iterations are needed, etc.\n",
    "\n",
    "(d) **Extra credit - 10 points** You will get extra credit if your GD implementation of linear regression achieves MSE very close to the least-square solution given by the package.\n",
    "\n",
    "(e) **Extra credit - 10 points** You will extra credit if your GD implementation of linear regression can run on the entire ''kc\\_house\\_data.csv'' dataset efficiently. Report the running time of your training algorithm for the entire dataset and compare that with the running time of the package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running\n"
     ]
    }
   ],
   "source": [
    "class Grad_lin:\n",
    "    # has a coeficients property\n",
    "    # has a fit method\n",
    "\n",
    "    def __init__(self, threshold, alpha, limit=1000):\n",
    "        self._rss = 0\n",
    "        self.n = 0\n",
    "        self._tss = 0\n",
    "        self._alpha = alpha\n",
    "        self.threshold = threshold\n",
    "        self._limit = limit\n",
    "\n",
    "    def get_alpha(self):\n",
    "        return self._alpha\n",
    "\n",
    "    def derivative(self, X, y, j):\n",
    "        # TODO replace with NumPy optimised iterator\n",
    "        d = 0\n",
    "        for i in range(len(X)):\n",
    "            # Good chance this X is wrong here:\n",
    "            # If there are errors on this line, make sure you're getting the ROW i\n",
    "            d += (self._theta.dot(X[i]) - y[i])*X[i, j]\n",
    "        ret = (d*2)/len(X)\n",
    "        return ret\n",
    "\n",
    "    def h(self, x, theta):\n",
    "        x = np.array([x]).T\n",
    "        return theta.T.dot(x)\n",
    "\n",
    "    def cost(self, X, y, theta):\n",
    "        return np.sum(np.power(X.dot(theta) - y, 2))/len(X)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        intercept = np.ones(len(X))\n",
    "        limit = self._limit\n",
    "\n",
    "        X = np.column_stack((intercept, X))\n",
    "        dt = self.threshold + 1\n",
    "        y = np.array([y]).T\n",
    "        self.n = len(X)\n",
    "        n = 0\n",
    "        last_cost = 0\n",
    "        self._theta = np.zeros([X.shape[1], 1])\n",
    "\n",
    "        # This is really hacky\n",
    "        self._old_theta = self._theta + 1\n",
    "        self._cost = np.zeros((limit, 1))\n",
    "\n",
    "        # while not converged\n",
    "        while ((np.linalg.norm(self._theta - self._old_theta) > self.threshold) and (n < limit)):\n",
    "            self._old_theta = self._theta.copy()\n",
    "            for j in range(len(self._theta)):\n",
    "                diff = 0\n",
    "                #here we try to use matrix operations where possible to make use of numpy optimisations\n",
    "                hmatrix = X.dot(self._old_theta)\n",
    "                diff = np.sum(np.multiply((hmatrix - y), X[:, j]))\n",
    "                self._theta[j] = self._old_theta[j]-self._alpha*diff/len(X)\n",
    "            self._cost[n, 0] = self.cost(X, y, self._theta)\n",
    "            last_cost = self._cost[n-1, 0]\n",
    "            #print(self._cost[n, 0], end = \",\")\n",
    "            n += 1\n",
    "        return self\n",
    "\n",
    "    def coef(self):\n",
    "        return self._theta[1:]\n",
    "\n",
    "    def intercept(self):\n",
    "        return self._theta[0]\n",
    "\n",
    "    def rss(self, X, y):\n",
    "        \"\"\"Function assumes no leading ones\"\"\"\n",
    "        rss = 0\n",
    "        for i in range(len(X)):\n",
    "            rss += (y[i] - self.predict(X[i, :]))**2\n",
    "        return rss\n",
    "\n",
    "    def tss(self, X, y):\n",
    "        \"\"\"Function assumes no leading ones\"\"\"\n",
    "        tss = 0\n",
    "        for i in range(len(X)):\n",
    "            tss += (y[i] - y.mean())**2\n",
    "        return tss\n",
    "\n",
    "    def mse(self, X, y):\n",
    "        \"\"\"Function assumes no leading ones\"\"\"\n",
    "        return (self.rss(X, y) / len(X))\n",
    "\n",
    "    def r2(self, X, y):\n",
    "        return 1-(self.rss(X, y)/self.tss(X, y))\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Takes a list of features for a single point, not including a leading 1\"\"\"\n",
    "        return self._theta.T.dot(np.insert(np.array(x), 0, 1))\n",
    "\n",
    "\n",
    "print(\"Running\")\n",
    "\n",
    "X = standardize(housing_training_features)\n",
    "y = housing_training_labels\n",
    "\n",
    "# Create a big table\n",
    "\n",
    "thetatable = pd.DataFrame()\n",
    "alpha = 0.000005\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        lim = (j+1)*25\n",
    "        gradmod = Grad_lin(0.0001, alpha*2, lim)\n",
    "        gradmod.fit(X, y)\n",
    "        thetatable[i, j] = np.insert(gradmod.coef(), 0, gradmod.intercept())\n",
    "        msetable = gradmod.mse(X, y)\n",
    "\n",
    "display(thetatable)\n",
    "#lines = bigtable.plot.line()\n",
    "\n",
    "gradmod = Grad_lin(0.0001, 0.00005, 100)\n",
    "gradmod.fit(X, y)\n",
    "print(\"RSS of training: \", gradmod.rss(X, y))\n",
    "print(\"R^2 of training: \", gradmod.r2(X, y))\n",
    "print(\"MSE of training: \", gradmod.mse(X, y))\n",
    "\n",
    "print(\"MSE of test: \", gradmod.mse(standardize(housing_testing_features), housing_testing_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4 Discussion\n",
    "\n",
    "Since $\\theta$ is a large matrix, it seems that the value of visualisaing the value of $\\theta$ for 25 combinations of $\\alpha$ and the number of iterations will show little. Instead, a line graph can succinctly visualise this data for each of the parameters. This decision was made because a 450 element table seems uninterpretable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 [Ridge Regression]\n",
    "Derivation of the closed form solution of Ridge Regression\n",
    "\n",
    "Begin with the definition of the loss function:\n",
    "\n",
    "$$J(\\theta)=\\frac{1}{2}\\sum_{i=1}^n{[h_\\theta(x^{(i)})-y^{(i)}}]^2+\\frac{1}{2}\\lambda \\sum_{j=1}^d{\\theta_j^2}$$\n",
    "$$\\begin{align}\n",
    "y=&x\\\\\n",
    "=&0\n",
    "\\end{align}\n",
    "$$\n",
    "where $d$ is the dimensions of the training data\\\\\n",
    "$h_\\theta(x)=\\sum_{m=0}^d{\\theta_mx_m}$\\\\\n",
    "$x^{(i)}$ denotes the $i$th datapoint of the training dataset\n",
    "\n",
    "We resolve to find the minima of a convex function defined by the cost function $J(\\theta)$\n",
    "\n",
    "Generally the approach will be to \n",
    "\\begin{enumerate}\n",
    "    \\item Find the gradient of the function $J(\\theta)$\n",
    "    \n",
    "    \n",
    "\\end{enumerate}\n",
    "\n",
    "\n",
    "Derivation of the closed form solution of Ridge Regression\n",
    "\n",
    "Begin with the definition of the loss function:\\\\\n",
    "$$J(\\theta)=\\frac{1}{2}\\sum_{i=1}^n{[h_\\theta(x^{(i)})-y^{(i)}}]^2+\\frac{1}{2}\\lambda \\sum_{j=1}^d{\\theta_j^2}$$\n",
    "where $d$ is the dimensions of the training data\n",
    "\n",
    "$h_\\theta(x)=\\sum_{m=0}^d{\\theta_mx_m}$\n",
    "\n",
    "\n",
    "$x^{(i)}$ denotes the $i$th datapoint of the training dataset\n",
    "\n",
    "We resolve to find the minima of a convex function defined by the cost function $J(\\theta)$\n",
    "\n",
    "Generally the approach will be to:\n",
    "\\begin{enumerate}\n",
    "    \\item Find the gradient of the function $J(\\theta)$\n",
    "    \\item Set the gradient to zero\n",
    "    \\item Solve for the $\\theta$\n",
    "\\end{enumerate}\n",
    "$$J(\\theta)=\\frac{1}{2}\\sum_{i=1}^n{[h_\\theta(x^{(i)})-y^{(i)}]}^2+\\frac{1}{2}\\lambda \\sum_{j=1}^d{\\theta_j^2}$$\n",
    "\n",
    "$$$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J\\theta)}{\\partial\\theta_l}\\\\\n",
    "    = & \\frac{\\partial}{\\partial \\theta_l}\\frac{1}{2}\n",
    "    \\left[\n",
    "        \\sum_{i=1}^n\n",
    "        {\n",
    "        \\left[\n",
    "            \\theta_0+\\theta_1x_1^{(i)}+\\theta_2x_2^{(i)}+\\dots+\\theta_l x_l^{(i)}\n",
    "        \\right]\n",
    "        }\n",
    "        -y^{(i)}\n",
    "    \\right]^2\n",
    "    +\\frac{\\partial}{\\partial \\theta_l}\n",
    "    \\left[\n",
    "        \\frac{\\lambda}{2}\n",
    "        \\sum_{j=1}^d{\\theta_j}\n",
    "    \\right]\\\\\n",
    "$$\n",
    "\n",
    "For readability we now take the left half of the sum to compute\n",
    "$$\n",
    "    \\frac{\\partial}{\\partial \\theta_l}\\frac{1}{2}\n",
    "    \\left[\n",
    "        \\sum_{i=1}^n\n",
    "        {\n",
    "        \\left[\n",
    "            \\theta_0+\\theta_1x_1^{(i)}+\\theta_2x_2^{(i)}+\\dots+\\theta_l x_l^{(i)}\n",
    "        \\right]\n",
    "        }\n",
    "        -y^{(i)}\n",
    "    \\right]^2\\\\\n",
    "    = \\frac{1}{2}\\left[\\sum_{i=1}^n\n",
    "    \\left[\n",
    "        \\frac{\\partial}{\\partial \\theta_l}\\left(\\theta_0\\right)\n",
    "        +\\frac{\\partial}{\\partial \\theta_l}\\left(\\theta_1x_1^{(i)}\\right)\n",
    "        +\\frac{\\partial}{\\partial \\theta_l}\\left(\\theta_2x_2^{(i)}\\right)\n",
    "        + \\dots\n",
    "        +\\frac{\\partial}{\\partial \\theta_l}\\left(\\theta_l x_l^{(i)}\\right)\n",
    "        + \\dots\n",
    "        +\\frac{\\partial}{\\partial \\theta_l}\\left(\\theta_k x_k^{(i)}\\right)\n",
    "    \\right]-\\frac{\\partial}{\\partial \\theta_l}y^{(i)}\n",
    "    \\right]\\\\\n",
    "    \\cdot 2 \\cdot \\left[ \\sum_{i=0}^n{\n",
    "    \\left[\n",
    "        \\sum_{k=0}^d\n",
    "        {\n",
    "        \\left[\n",
    "            \\theta_k x_k^{(i)}\n",
    "        \\right] -y^{(i)}\n",
    "        }\n",
    "    \\right]\n",
    "    }\\right]\\\\\n",
    "    = x_l^{(i)}\\sum_{i=1}^n\n",
    "    \\left[\n",
    "        \\sum_{k=0}^d\n",
    "        {\\left[\n",
    "            \\left(\\theta_kx_k^{(i)}\\right) - y^{(i)}\n",
    "        \\right]}\n",
    "    \\right]\n",
    "$$\n",
    "For $0<l\\leq k$\n",
    "\n",
    "Now to reintroduce the right hand sum\n",
    "$$\n",
    "        \\frac{\\partial}{\\partial \\theta_l}\n",
    "    \\left[\n",
    "        \\frac{\\lambda}{2}\n",
    "        \\sum_{j=1}^d{\\theta_j}\n",
    "    \\right]\\\\\n",
    "    = \\frac{\\lambda}{2}\\cdot 2 \\theta_L\\\\\n",
    "    = \\lambda\\theta_l\n",
    "$$\n",
    "Given that $l\\in[1,d]$}\n",
    "\n",
    "Combining equations again\n",
    "$$\n",
    "          \\frac{\\partial J(\\theta)}{\\partial}\n",
    " x_l^{(i)}\\sum_{i=1}^n\n",
    "    \\left[\n",
    "        \\sum_{k=0}^d\n",
    "        {\\left[\n",
    "            \\left(\\theta_k x_k^{(i)}\\right) - y^{(i)}\n",
    "        \\right]}\n",
    "    \\right]\n",
    "    +\n",
    "    \\lambda\\theta_l =0\\\\\n",
    "    = x_l^{(i)}\\sum_{i=1}^n\n",
    "    \\left[\n",
    "        h_\\theta(x^{(i)}) - y^{(i)}\n",
    "    \\right]\n",
    "    +\n",
    "    \\lambda\\theta_l =0\\\\\n",
    "    = \\sum_{i=1}^n\n",
    "    x_l^{(i)}\n",
    "    {\\left[\n",
    "        \\sum_{k=0}^{l-1}\n",
    "        {\\left[\n",
    "            \\left(\\theta_k x_k^{(i)}\\right) - y^{(i)}\n",
    "        \\right]}\n",
    "        +\n",
    "        \\left(\\theta_lx+l^{(i)}\\right)\n",
    "        +\n",
    "        \\sum_{k=l+1}^d\n",
    "        {\\left[\n",
    "            \\left(\\theta_k x_k^{(i)}\\right) - y^{(i)}\n",
    "        \\right]}\n",
    "    \\right]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
